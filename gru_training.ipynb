{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73221008",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import atp_graph, losses\n",
    "from data import synthetic_data_gen, feature_extractor\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from model import atp_pipeline\n",
    "from comparison_models.gru.gru import gru_model\n",
    "from comparison_models.gru import gru_pipeline\n",
    "from data import dataset_preparer\n",
    "from Tutorials.helper import batcher\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2343a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "    n_C = 10\n",
    "    n_T = 10\n",
    "\n",
    "    batch_size = 1\n",
    "    test_batch_s = 100\n",
    "\n",
    "    nll_list = []\n",
    "    mse_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d6153a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = 'weights/forecasting/weather/gru/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "717a5d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'weather'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04ccd0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_val, y_val, x_test, y_test = dataset_preparer.weather_processor(path_to_weather_data=\"datasets/weather.csv\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "075afc3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Max\n",
      "Tensor(\"gru_pipeline/argsort/TopKV2:1\", shape=(1, 10), dtype=int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-05 11:11:43.944309: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-05-05 11:11:43.944884: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 20, 20)\n",
      "(32, 20, 20)\n",
      "(32, 20, 10)\n",
      "Tensor(\"gru_pipeline/argsort/TopKV2:1\", shape=(1, 10), dtype=int32)\n",
      "(32, 20, 20)\n",
      "(32, 20, 20)\n",
      "(32, 20, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-05 11:11:45.425163: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"gru_pipeline_1/argsort/TopKV2:1\", shape=(1, 10), dtype=int32)\n",
      "(32, 20, 20)\n",
      "(32, 20, 20)\n",
      "(32, 20, 10)\n",
      "Tensor(\"gru_pipeline_1/argsort/TopKV2:1\", shape=(1, 10), dtype=int32)\n",
      "(32, 20, 20)\n",
      "(32, 20, 20)\n",
      "(32, 20, 10)\n",
      "Tensor(\"gru_pipeline_2/argsort/TopKV2:1\", shape=(1, 10), dtype=int32)\n",
      "(32, 20, 20)\n",
      "(32, 20, 20)\n",
      "(32, 20, 10)\n",
      "Tensor(\"gru_pipeline_2/argsort/TopKV2:1\", shape=(1, 10), dtype=int32)\n",
      "(32, 20, 20)\n",
      "(32, 20, 20)\n",
      "(32, 20, 10)\n",
      "Tensor(\"gru_pipeline_3/argsort/TopKV2:1\", shape=(1, 10), dtype=int32)\n",
      "(32, 20, 20)\n",
      "(32, 20, 20)\n",
      "(32, 20, 10)\n",
      "Tensor(\"gru_pipeline_3/argsort/TopKV2:1\", shape=(1, 10), dtype=int32)\n",
      "(32, 20, 20)\n",
      "(32, 20, 20)\n",
      "(32, 20, 10)\n",
      "Tensor(\"gru_pipeline_4/argsort/TopKV2:1\", shape=(1, 10), dtype=int32)\n",
      "(32, 20, 20)\n",
      "(32, 20, 20)\n",
      "(32, 20, 10)\n",
      "Tensor(\"gru_pipeline_4/argsort/TopKV2:1\", shape=(1, 10), dtype=int32)\n",
      "(32, 20, 20)\n",
      "(32, 20, 20)\n",
      "(32, 20, 10)\n",
      "Tensor(\"gru_pipeline_5/argsort/TopKV2:1\", shape=(1, 10), dtype=int32)\n",
      "(32, 20, 20)\n",
      "(32, 20, 20)\n",
      "(32, 20, 10)\n",
      "Tensor(\"gru_pipeline_5/argsort/TopKV2:1\", shape=(1, 10), dtype=int32)\n",
      "(32, 20, 20)\n",
      "(32, 20, 20)\n",
      "(32, 20, 10)\n",
      "Tensor(\"gru_pipeline_6/argsort/TopKV2:1\", shape=(1, 10), dtype=int32)\n",
      "(32, 20, 20)\n",
      "(32, 20, 20)\n",
      "(32, 20, 10)\n",
      "Tensor(\"gru_pipeline_6/argsort/TopKV2:1\", shape=(1, 10), dtype=int32)\n",
      "(32, 20, 20)\n",
      "(32, 20, 20)\n",
      "(32, 20, 10)\n",
      "Tensor(\"gru_pipeline_7/argsort/TopKV2:1\", shape=(1, 10), dtype=int32)\n",
      "(32, 20, 20)\n",
      "(32, 20, 20)\n",
      "(32, 20, 10)\n",
      "Tensor(\"gru_pipeline_7/argsort/TopKV2:1\", shape=(1, 10), dtype=int32)\n",
      "(32, 20, 20)\n",
      "(32, 20, 20)\n",
      "(32, 20, 10)\n",
      "Tensor(\"gru_pipeline_8/argsort/TopKV2:1\", shape=(1, 10), dtype=int32)\n",
      "(32, 20, 20)\n",
      "(32, 20, 20)\n",
      "(32, 20, 10)\n",
      "Tensor(\"gru_pipeline_8/argsort/TopKV2:1\", shape=(1, 10), dtype=int32)\n",
      "(32, 20, 20)\n",
      "(32, 20, 20)\n",
      "(32, 20, 10)\n",
      "Tensor(\"gru_pipeline_9/argsort/TopKV2:1\", shape=(1, 10), dtype=int32)\n",
      "(32, 20, 20)\n",
      "(32, 20, 20)\n",
      "(32, 20, 10)\n",
      "Tensor(\"gru_pipeline_9/argsort/TopKV2:1\", shape=(1, 10), dtype=int32)\n",
      "(32, 20, 20)\n",
      "(32, 20, 20)\n",
      "(32, 20, 10)\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/CPU:0\"):\n",
    "\n",
    "    for i in range(10):\n",
    "\n",
    "        step = 1\n",
    "        run= 67 + i\n",
    "        tf.random.set_seed(run)\n",
    "\n",
    "        model = gru_pipeline.instantiate_gru(dataset)\n",
    "        tr_step = atp_graph.build_graph()\n",
    "\n",
    "        ###### can we put the name of the model into the folder name #########?\n",
    "\n",
    "        name_comp = 'run_' + str(run)\n",
    "        folder = save_dir + '/ckpt/check_' + name_comp\n",
    "        if not os.path.exists(folder): os.mkdir(folder)\n",
    "        opt = tf.keras.optimizers.Adam(3e-4)\n",
    "        ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=opt, net=model)\n",
    "        manager = tf.train.CheckpointManager(ckpt, folder, max_to_keep=1)\n",
    "        ckpt.restore(manager.latest_checkpoint) \n",
    "        sum_mse_tot = 0; sum_nll_tot = 0\n",
    "        mini = 50000\n",
    "\n",
    "        \n",
    "        for i in range(10):\n",
    "            idx_list = list(range(x_train.shape[0] - (n_C+n_T)))\n",
    "            x,y,_ = batcher(x_train,y_train,idx_list,window=n_C+n_T) ####### generalise for not just forecasting\n",
    "            _,_, _, _ = tr_step(model, opt, x, y, n_C, n_T, training=True)\n",
    "\n",
    "#             if i % 100 == 0:\n",
    "#                 idx_list = list(range(x_val.shape[0] - (n_C+n_T)))\n",
    "#                 t_te,y_te,_ = batcher(x_val, y_val, idx_list, batch_s = 100, window=n_C+n_T)\n",
    "#                 μ, log_σ = model([t_te, y_te, n_C, n_T, False])\n",
    "#                 _,_,_, nll_pp_te, msex_te = losses.nll(y_te[:, n_C:n_C+n_T], μ, log_σ)\n",
    "\n",
    "#                 if nll_pp_te < mini:\n",
    "#                     mini = nll_pp_te\n",
    "#                     manager.save()\n",
    "#                     step += 1\n",
    "#                     ckpt.step.assign_add(1)\n",
    "\n",
    "#         ckpt = tf.train.Checkpoint(step=tf.Variable(step), optimizer=opt, net=model)\n",
    "#         manager = tf.train.CheckpointManager(ckpt, folder, max_to_keep=1)\n",
    "#         ckpt.restore(manager.latest_checkpoint) \n",
    "   \n",
    "        \n",
    "#         idx_list = list(range(x_test.shape[0] - (n_C+n_T)))\n",
    "#         num_batches = len(idx_list)//test_batch_s\n",
    "\n",
    "#         for _ in range(num_batches): #### specify correct number of batches for the batcher #####\n",
    "#             if(_ == (num_batches-1)): test_batch_s = len(idx_list)        \n",
    "#             t_te,y_te,idx_list = batcher(x_test, y_test, idx_list,batch_s = test_batch_s, window=n_C+n_T)\n",
    "#             μ, log_σ = model([t_te, y_te, n_C, n_T, False])\n",
    "#             _, sum_mse, sum_nll, _, _ = losses.nll(y_te[:, n_C:n_C+n_T], μ, log_σ)\n",
    "#             sum_nll_tot += sum_nll / n_T\n",
    "#             sum_mse_tot += sum_mse / n_T\n",
    "\n",
    "#         nllx =  sum_nll_tot / (test_batch_s * x_test.shape[0]//test_batch_s)\n",
    "#         msex =  sum_mse_tot / (test_batch_s * x_test.shape[0]//test_batch_s)\n",
    "\n",
    "\n",
    "#         nll_list.append(nllx.numpy())\n",
    "#         mse_list.append(msex.numpy())\n",
    "                \n",
    "            \n",
    "#         np.save(save_dir + '/nll_list.npy', nll_list)    \n",
    "#         np.save(save_dir + '/mse_list.npy', mse_list)  \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
