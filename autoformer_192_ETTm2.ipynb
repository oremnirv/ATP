{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a418054b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6d2b2a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "elc = pd.read_csv('datasets/ETTm2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58d1b426",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "35dbaae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69680, 8)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf8fd709",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x127564c70>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(elc.OT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "50396bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "a972fe94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.tseries import offsets\n",
    "from pandas.tseries.frequencies import to_offset\n",
    "\n",
    "\n",
    "class TimeFeature:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "        pass\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + \"()\"\n",
    "\n",
    "\n",
    "class SecondOfMinute(TimeFeature):\n",
    "    \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "        return index.second / 59.0 - 0.5\n",
    "\n",
    "\n",
    "class MinuteOfHour(TimeFeature):\n",
    "    \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "        return index.minute / 59.0 - 0.5\n",
    "\n",
    "\n",
    "class HourOfDay(TimeFeature):\n",
    "    \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "        return index.hour / 23.0 - 0.5\n",
    "\n",
    "\n",
    "class DayOfWeek(TimeFeature):\n",
    "    \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "        return index.dayofweek / 6.0 - 0.5\n",
    "\n",
    "\n",
    "class DayOfMonth(TimeFeature):\n",
    "    \"\"\"Day of month encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "        return (index.day - 1) / 30.0 - 0.5\n",
    "\n",
    "\n",
    "class DayOfYear(TimeFeature):\n",
    "    \"\"\"Day of year encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "        return (index.dayofyear - 1) / 365.0 - 0.5\n",
    "\n",
    "\n",
    "class MonthOfYear(TimeFeature):\n",
    "    \"\"\"Month of year encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "        return (index.month - 1) / 11.0 - 0.5\n",
    "\n",
    "\n",
    "class WeekOfYear(TimeFeature):\n",
    "    \"\"\"Week of year encoded as value between [-0.5, 0.5]\"\"\"\n",
    "\n",
    "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
    "        return (index.isocalendar().week - 1) / 52.0 - 0.5\n",
    "\n",
    "\n",
    "def time_features_from_frequency_str(freq_str: str) -> List[TimeFeature]:\n",
    "    \"\"\"\n",
    "    Returns a list of time features that will be appropriate for the given frequency string.\n",
    "    Parameters\n",
    "    ----------\n",
    "    freq_str\n",
    "        Frequency string of the form [multiple][granularity] such as \"12H\", \"5min\", \"1D\" etc.\n",
    "    \"\"\"\n",
    "\n",
    "    features_by_offsets = {\n",
    "        offsets.YearEnd: [],\n",
    "        offsets.QuarterEnd: [MonthOfYear],\n",
    "        offsets.MonthEnd: [MonthOfYear],\n",
    "        offsets.Week: [DayOfMonth, WeekOfYear],\n",
    "        offsets.Day: [DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.BusinessDay: [DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.Hour: [HourOfDay, DayOfWeek, DayOfMonth, DayOfYear],\n",
    "        offsets.Minute: [\n",
    "            MinuteOfHour,\n",
    "            HourOfDay,\n",
    "            DayOfWeek,\n",
    "            DayOfMonth,\n",
    "            DayOfYear,\n",
    "        ],\n",
    "        offsets.Second: [\n",
    "            SecondOfMinute,\n",
    "            MinuteOfHour,\n",
    "            HourOfDay,\n",
    "            DayOfWeek,\n",
    "            DayOfMonth,\n",
    "            DayOfYear,\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    offset = to_offset(freq_str)\n",
    "\n",
    "    for offset_type, feature_classes in features_by_offsets.items():\n",
    "        if isinstance(offset, offset_type):\n",
    "            return [cls() for cls in feature_classes]\n",
    "\n",
    "    supported_freq_msg = f\"\"\"\n",
    "    Unsupported frequency {freq_str}\n",
    "    The following frequencies are supported:\n",
    "        Y   - yearly\n",
    "            alias: A\n",
    "        M   - monthly\n",
    "        W   - weekly\n",
    "        D   - daily\n",
    "        B   - business days\n",
    "        H   - hourly\n",
    "        T   - minutely\n",
    "            alias: min\n",
    "        S   - secondly\n",
    "    \"\"\"\n",
    "    raise RuntimeError(supported_freq_msg)\n",
    "\n",
    "\n",
    "def time_features(dates, freq='h'):\n",
    "    return np.vstack([feat(dates) for feat in time_features_from_frequency_str(freq)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "c15dce13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "4fd3c035",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Dataset_Custom(Dataset):\n",
    "    def __init__(self, flag='train', size=[192, 48, 96],\n",
    "                 features='S',\n",
    "                 target='OT', scale=True, timeenc=0, freq='h'):\n",
    "        # size [seq_len, label_len, pred_len]\n",
    "        # info\n",
    "        if size == None:\n",
    "            self.seq_len = 24 * 4 * 4\n",
    "            self.label_len = 24 * 4\n",
    "            self.pred_len = 24 * 4\n",
    "        else:\n",
    "            self.seq_len = size[0]\n",
    "            self.label_len = size[1]\n",
    "            self.pred_len = size[2]\n",
    "        # init\n",
    "        assert flag in ['train', 'test', 'val']\n",
    "        type_map = {'train': 0, 'val': 1, 'test': 2}\n",
    "        self.set_type = type_map[flag]\n",
    "\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "        self.scale = scale\n",
    "        self.timeenc = timeenc\n",
    "        self.freq = freq\n",
    "\n",
    "        self.__read_data__()\n",
    "\n",
    "    def __read_data__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "        df_raw = pd.read_csv('datasets/ETTm2.csv')\n",
    "\n",
    "        '''\n",
    "        df_raw.columns: ['date', ...(other features), target feature]\n",
    "        '''\n",
    "        cols = list(df_raw.columns)\n",
    "        cols.remove(self.target)\n",
    "        cols.remove('date')\n",
    "        df_raw = df_raw[['date'] + cols + [self.target]]\n",
    "        # print(cols)\n",
    "        num_train = int(len(df_raw) * 0.7)\n",
    "        num_test = int(len(df_raw) * 0.2)\n",
    "        num_vali = len(df_raw) - num_train - num_test\n",
    "        border1s = [0, num_train - self.seq_len, len(df_raw) - num_test - self.seq_len]\n",
    "        border2s = [num_train, num_train + num_vali, len(df_raw)]\n",
    "        border1 = border1s[self.set_type]\n",
    "        border2 = border2s[self.set_type]\n",
    "\n",
    "        if self.features == 'M' or self.features == 'MS':\n",
    "            cols_data = df_raw.columns[1:]\n",
    "            df_data = df_raw[cols_data]\n",
    "        elif self.features == 'S':\n",
    "            df_data = df_raw[[self.target]]\n",
    "\n",
    "        if self.scale:\n",
    "            train_data = df_data[border1s[0]:border2s[0]]\n",
    "            self.scaler.fit(train_data.values)\n",
    "            data = self.scaler.transform(df_data.values)\n",
    "        else:\n",
    "            data = df_data.values\n",
    "\n",
    "        df_stamp = df_raw[['date']][border1:border2]\n",
    "        df_stamp['date'] = pd.to_datetime(df_stamp.date)\n",
    "        if self.timeenc == 0:\n",
    "            df_stamp['month'] = df_stamp.date.apply(lambda row: row.month, 1)\n",
    "            df_stamp['day'] = df_stamp.date.apply(lambda row: row.day, 1)\n",
    "            df_stamp['weekday'] = df_stamp.date.apply(lambda row: row.weekday(), 1)\n",
    "            df_stamp['hour'] = df_stamp.date.apply(lambda row: row.hour, 1)\n",
    "            data_stamp = df_stamp.drop(['date'], 1).values\n",
    "        elif self.timeenc == 1:\n",
    "            data_stamp = time_features(pd.to_datetime(df_stamp['date'].values), freq=self.freq)\n",
    "            data_stamp = data_stamp.transpose(1, 0)\n",
    "\n",
    "        self.data_x = data[border1:border2]\n",
    "        self.data_y = data[border1:border2]\n",
    "        self.data_stamp = data_stamp\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        s_begin = index\n",
    "        s_end = s_begin + self.seq_len\n",
    "        r_begin = s_end - self.label_len\n",
    "        r_end = r_begin + self.label_len + self.pred_len\n",
    "\n",
    "        seq_x = self.data_x[s_begin:s_end]\n",
    "        seq_y = self.data_y[r_begin:r_end]\n",
    "        seq_x_mark = self.data_stamp[s_begin:s_end]\n",
    "        seq_y_mark = self.data_stamp[r_begin:r_end]\n",
    "\n",
    "        return seq_x, seq_y, seq_x_mark, seq_y_mark\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_x) - self.seq_len - self.pred_len + 1\n",
    "\n",
    "    def inverse_transform(self, data):\n",
    "        return self.scaler.inverse_transform(data)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "490aca5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "6e36dfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import weight_norm\n",
    "import math\n",
    "\n",
    "def compared_version(ver1, ver2):\n",
    "    \"\"\"\n",
    "    :param ver1\n",
    "    :param ver2\n",
    "    :return: ver1< = >ver2 False/True\n",
    "    \"\"\"\n",
    "    list1 = str(ver1).split(\".\")\n",
    "    list2 = str(ver2).split(\".\")\n",
    "    \n",
    "    for i in range(len(list1)) if len(list1) < len(list2) else range(len(list2)):\n",
    "        if int(list1[i]) == int(list2[i]):\n",
    "            pass\n",
    "        elif int(list1[i]) < int(list2[i]):\n",
    "            return -1\n",
    "        else:\n",
    "            return 1\n",
    "    \n",
    "    if len(list1) == len(list2):\n",
    "        return True\n",
    "    elif len(list1) < len(list2):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model).float()\n",
    "        pe.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, max_len).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pe[:, :x.size(1)]\n",
    "\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        padding = 1 if compared_version(torch.__version__, '1.5.0') else 2\n",
    "        self.tokenConv = nn.Conv1d(in_channels=c_in, out_channels=d_model,\n",
    "                                   kernel_size=3, padding=padding, padding_mode='circular', bias=False)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.tokenConv(x.permute(0, 2, 1)).transpose(1, 2)\n",
    "        return x\n",
    "\n",
    "\n",
    "class FixedEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(FixedEmbedding, self).__init__()\n",
    "\n",
    "        w = torch.zeros(c_in, d_model).float()\n",
    "        w.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, c_in).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        w[:, 0::2] = torch.sin(position * div_term)\n",
    "        w[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        self.emb = nn.Embedding(c_in, d_model)\n",
    "        self.emb.weight = nn.Parameter(w, requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.emb(x).detach()\n",
    "\n",
    "\n",
    "class TemporalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='timeF', freq='h'):\n",
    "        super(TemporalEmbedding, self).__init__()\n",
    "\n",
    "        minute_size = 4\n",
    "        hour_size = 24\n",
    "        weekday_size = 7\n",
    "        day_size = 32\n",
    "        month_size = 13\n",
    "\n",
    "        Embed = FixedEmbedding if embed_type == 'fixed' else nn.Embedding\n",
    "        if freq == 't':\n",
    "            self.minute_embed = Embed(minute_size, d_model)\n",
    "        self.hour_embed = Embed(hour_size, d_model)\n",
    "        self.weekday_embed = Embed(weekday_size, d_model)\n",
    "        self.day_embed = Embed(day_size, d_model)\n",
    "        self.month_embed = Embed(month_size, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.long()\n",
    "\n",
    "        minute_x = self.minute_embed(x[:, :, 4]) if hasattr(self, 'minute_embed') else 0.\n",
    "        hour_x = self.hour_embed(x[:, :, 3])\n",
    "        weekday_x = self.weekday_embed(x[:, :, 2])\n",
    "        day_x = self.day_embed(x[:, :, 1])\n",
    "        month_x = self.month_embed(x[:, :, 0])\n",
    "\n",
    "        return hour_x + weekday_x + day_x + month_x + minute_x\n",
    "\n",
    "\n",
    "class TimeFeatureEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='timeF', freq='h'):\n",
    "        super(TimeFeatureEmbedding, self).__init__()\n",
    "\n",
    "        freq_map = {'h': 4, 't': 5, 's': 6, 'm': 1, 'a': 1, 'w': 2, 'd': 3, 'b': 3}\n",
    "        d_inp = freq_map[freq]\n",
    "        self.embed = nn.Linear(d_inp, d_model, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embed(x)\n",
    "\n",
    "\n",
    "class DataEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model, embed_type='timeF', freq='h', dropout=0.1):\n",
    "        super(DataEmbedding, self).__init__()\n",
    "\n",
    "        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n",
    "        self.position_embedding = PositionalEmbedding(d_model=d_model)\n",
    "        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type,\n",
    "                                                    freq=freq) if embed_type != 'timeF' else TimeFeatureEmbedding(\n",
    "            d_model=d_model, embed_type=embed_type, freq=freq)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x, x_mark):\n",
    "        x = self.value_embedding(x) + self.temporal_embedding(x_mark) + self.position_embedding(x)\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class DataEmbedding_wo_pos(nn.Module):\n",
    "    def __init__(self, c_in, d_model, embed_type='timeF', freq='h', dropout=0.1):\n",
    "        super(DataEmbedding_wo_pos, self).__init__()\n",
    "\n",
    "        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n",
    "        self.position_embedding = PositionalEmbedding(d_model=d_model)\n",
    "        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type,\n",
    "                                                    freq=freq) if embed_type != 'timeF' else TimeFeatureEmbedding(\n",
    "            d_model=d_model, embed_type=embed_type, freq=freq)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x, x_mark):\n",
    "        x = self.value_embedding(x) + self.temporal_embedding(x_mark)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "d977b06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class my_Layernorm(nn.Module):\n",
    "    \"\"\"\n",
    "    Special designed layernorm for the seasonal part\n",
    "    \"\"\"\n",
    "    def __init__(self, channels):\n",
    "        super(my_Layernorm, self).__init__()\n",
    "        self.layernorm = nn.LayerNorm(channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_hat = self.layernorm(x)\n",
    "        bias = torch.mean(x_hat, dim=1).unsqueeze(1).repeat(1, x.shape[1], 1)\n",
    "        return x_hat - bias\n",
    "\n",
    "\n",
    "class moving_avg(nn.Module):\n",
    "    \"\"\"\n",
    "    Moving average block to highlight the trend of time series\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size, stride):\n",
    "        super(moving_avg, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.avg = nn.AvgPool1d(kernel_size=kernel_size, stride=stride, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # padding on the both ends of time series\n",
    "        front = x[:, 0:1, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
    "        end = x[:, -1:, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
    "        x = torch.cat([front, x, end], dim=1)\n",
    "        x = self.avg(x.permute(0, 2, 1))\n",
    "        x = x.permute(0, 2, 1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class series_decomp(nn.Module):\n",
    "    \"\"\"\n",
    "    Series decomposition block\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size):\n",
    "        super(series_decomp, self).__init__()\n",
    "        self.moving_avg = moving_avg(kernel_size, stride=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        moving_mean = self.moving_avg(x)\n",
    "        res = x - moving_mean\n",
    "        return res, moving_mean\n",
    "\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Autoformer encoder layer with the progressive decomposition architecture\n",
    "    \"\"\"\n",
    "    def __init__(self, attention, d_model, d_ff=None, moving_avg=25, dropout=0.1, activation=\"relu\"):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        d_ff = d_ff or 4 * d_model\n",
    "        self.attention = attention\n",
    "        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1, bias=False)\n",
    "        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1, bias=False)\n",
    "        self.decomp1 = series_decomp(moving_avg)\n",
    "        self.decomp2 = series_decomp(moving_avg)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = F.relu if activation == \"relu\" else F.gelu\n",
    "\n",
    "    def forward(self, x, attn_mask=None):\n",
    "        new_x, attn = self.attention(\n",
    "            x, x, x,\n",
    "            attn_mask=attn_mask\n",
    "        )\n",
    "        x = x + self.dropout(new_x)\n",
    "        x, _ = self.decomp1(x)\n",
    "        y = x\n",
    "        y = self.dropout(self.activation(self.conv1(y.transpose(-1, 1))))\n",
    "        y = self.dropout(self.conv2(y).transpose(-1, 1))\n",
    "        res, _ = self.decomp2(x + y)\n",
    "        return res, attn\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Autoformer encoder\n",
    "    \"\"\"\n",
    "    def __init__(self, attn_layers, conv_layers=None, norm_layer=None):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.attn_layers = nn.ModuleList(attn_layers)\n",
    "        self.conv_layers = nn.ModuleList(conv_layers) if conv_layers is not None else None\n",
    "        self.norm = norm_layer\n",
    "\n",
    "    def forward(self, x, attn_mask=None):\n",
    "        attns = []\n",
    "        if self.conv_layers is not None:\n",
    "            for attn_layer, conv_layer in zip(self.attn_layers, self.conv_layers):\n",
    "                x, attn = attn_layer(x, attn_mask=attn_mask)\n",
    "                x = conv_layer(x)\n",
    "                attns.append(attn)\n",
    "            x, attn = self.attn_layers[-1](x)\n",
    "            attns.append(attn)\n",
    "        else:\n",
    "            for attn_layer in self.attn_layers:\n",
    "                x, attn = attn_layer(x, attn_mask=attn_mask)\n",
    "                attns.append(attn)\n",
    "\n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "\n",
    "        return x, attns\n",
    "\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Autoformer decoder layer with the progressive decomposition architecture\n",
    "    \"\"\"\n",
    "    def __init__(self, self_attention, cross_attention, d_model, c_out, d_ff=None,\n",
    "                 moving_avg=25, dropout=0.1, activation=\"relu\"):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        d_ff = d_ff or 4 * d_model\n",
    "        self.self_attention = self_attention\n",
    "        self.cross_attention = cross_attention\n",
    "        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1, bias=False)\n",
    "        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1, bias=False)\n",
    "        self.decomp1 = series_decomp(moving_avg)\n",
    "        self.decomp2 = series_decomp(moving_avg)\n",
    "        self.decomp3 = series_decomp(moving_avg)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.projection = nn.Conv1d(in_channels=d_model, out_channels=c_out, kernel_size=3, stride=1, padding=1,\n",
    "                                    padding_mode='circular', bias=False)\n",
    "        self.activation = F.relu if activation == \"relu\" else F.gelu\n",
    "\n",
    "    def forward(self, x, cross, x_mask=None, cross_mask=None):\n",
    "        x = x + self.dropout(self.self_attention(\n",
    "            x, x, x,\n",
    "            attn_mask=x_mask\n",
    "        )[0])\n",
    "        x, trend1 = self.decomp1(x)\n",
    "        x = x + self.dropout(self.cross_attention(\n",
    "            x, cross, cross,\n",
    "            attn_mask=cross_mask\n",
    "        )[0])\n",
    "        x, trend2 = self.decomp2(x)\n",
    "        y = x\n",
    "        y = self.dropout(self.activation(self.conv1(y.transpose(-1, 1))))\n",
    "        y = self.dropout(self.conv2(y).transpose(-1, 1))\n",
    "        x, trend3 = self.decomp3(x + y)\n",
    "\n",
    "        residual_trend = trend1 + trend2 + trend3\n",
    "        residual_trend = self.projection(residual_trend.permute(0, 2, 1)).transpose(1, 2)\n",
    "        return x, residual_trend\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Autoformer encoder\n",
    "    \"\"\"\n",
    "    def __init__(self, layers, norm_layer=None, projection=None):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        self.norm = norm_layer\n",
    "        self.projection = projection\n",
    "\n",
    "    def forward(self, x, cross, x_mask=None, cross_mask=None, trend=None):\n",
    "        for layer in self.layers:\n",
    "            x, residual_trend = layer(x, cross, x_mask=x_mask, cross_mask=cross_mask)\n",
    "            trend = trend + residual_trend\n",
    "\n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "\n",
    "        if self.projection is not None:\n",
    "            x = self.projection(x)\n",
    "        return x, trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "87c86840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "from math import sqrt\n",
    "import os\n",
    "\n",
    "\n",
    "class AutoCorrelation(nn.Module):\n",
    "    \"\"\"\n",
    "    AutoCorrelation Mechanism with the following two phases:\n",
    "    (1) period-based dependencies discovery\n",
    "    (2) time delay aggregation\n",
    "    This block can replace the self-attention family mechanism seamlessly.\n",
    "    \"\"\"\n",
    "    def __init__(self, mask_flag=True, factor=1, scale=None, attention_dropout=0.1, output_attention=False):\n",
    "        super(AutoCorrelation, self).__init__()\n",
    "        self.factor = factor\n",
    "        self.scale = scale\n",
    "        self.mask_flag = mask_flag\n",
    "        self.output_attention = output_attention\n",
    "        self.dropout = nn.Dropout(attention_dropout)\n",
    "\n",
    "    def time_delay_agg_training(self, values, corr):\n",
    "        \"\"\"\n",
    "        SpeedUp version of Autocorrelation (a batch-normalization style design)\n",
    "        This is for the training phase.\n",
    "        \"\"\"\n",
    "        head = values.shape[1]\n",
    "        channel = values.shape[2]\n",
    "        length = values.shape[3]\n",
    "        # find top k\n",
    "        top_k = int(self.factor * math.log(length))\n",
    "        mean_value = torch.mean(torch.mean(corr, dim=1), dim=1)\n",
    "        index = torch.topk(torch.mean(mean_value, dim=0), top_k, dim=-1)[1]\n",
    "        weights = torch.stack([mean_value[:, index[i]] for i in range(top_k)], dim=-1)\n",
    "        # update corr\n",
    "        tmp_corr = torch.softmax(weights, dim=-1)\n",
    "        # aggregation\n",
    "        tmp_values = values\n",
    "        delays_agg = torch.zeros_like(values).float()\n",
    "        for i in range(top_k):\n",
    "            pattern = torch.roll(tmp_values, -int(index[i]), -1)\n",
    "            delays_agg = delays_agg + pattern * \\\n",
    "                         (tmp_corr[:, i].unsqueeze(1).unsqueeze(1).unsqueeze(1).repeat(1, head, channel, length))\n",
    "        return delays_agg\n",
    "\n",
    "    def time_delay_agg_inference(self, values, corr):\n",
    "        \"\"\"\n",
    "        SpeedUp version of Autocorrelation (a batch-normalization style design)\n",
    "        This is for the inference phase.\n",
    "        \"\"\"\n",
    "        batch = values.shape[0]\n",
    "        head = values.shape[1]\n",
    "        channel = values.shape[2]\n",
    "        length = values.shape[3]\n",
    "        # index init\n",
    "        init_index = torch.arange(length).unsqueeze(0).unsqueeze(0).unsqueeze(0)\\\n",
    "            .repeat(batch, head, channel, 1).to(values.device)\n",
    "        # find top k\n",
    "        top_k = int(self.factor * math.log(length))\n",
    "        mean_value = torch.mean(torch.mean(corr, dim=1), dim=1)\n",
    "        weights, delay = torch.topk(mean_value, top_k, dim=-1)\n",
    "        # update corr\n",
    "        tmp_corr = torch.softmax(weights, dim=-1)\n",
    "        # aggregation\n",
    "        tmp_values = values.repeat(1, 1, 1, 2)\n",
    "        delays_agg = torch.zeros_like(values).float()\n",
    "        for i in range(top_k):\n",
    "            tmp_delay = init_index + delay[:, i].unsqueeze(1).unsqueeze(1).unsqueeze(1).repeat(1, head, channel, length)\n",
    "            pattern = torch.gather(tmp_values, dim=-1, index=tmp_delay)\n",
    "            delays_agg = delays_agg + pattern * \\\n",
    "                         (tmp_corr[:, i].unsqueeze(1).unsqueeze(1).unsqueeze(1).repeat(1, head, channel, length))\n",
    "        return delays_agg\n",
    "\n",
    "    def time_delay_agg_full(self, values, corr):\n",
    "        \"\"\"\n",
    "        Standard version of Autocorrelation\n",
    "        \"\"\"\n",
    "        batch = values.shape[0]\n",
    "        head = values.shape[1]\n",
    "        channel = values.shape[2]\n",
    "        length = values.shape[3]\n",
    "        # index init\n",
    "        init_index = torch.arange(length).unsqueeze(0).unsqueeze(0).unsqueeze(0)\\\n",
    "            .repeat(batch, head, channel, 1).to(values.device)\n",
    "        # find top k\n",
    "        top_k = int(self.factor * math.log(length))\n",
    "        weights, delay = torch.topk(corr, top_k, dim=-1)\n",
    "        # update corr\n",
    "        tmp_corr = torch.softmax(weights, dim=-1)\n",
    "        # aggregation\n",
    "        tmp_values = values.repeat(1, 1, 1, 2)\n",
    "        delays_agg = torch.zeros_like(values).float()\n",
    "        for i in range(top_k):\n",
    "            tmp_delay = init_index + delay[..., i].unsqueeze(-1)\n",
    "            pattern = torch.gather(tmp_values, dim=-1, index=tmp_delay)\n",
    "            delays_agg = delays_agg + pattern * (tmp_corr[..., i].unsqueeze(-1))\n",
    "        return delays_agg\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask):\n",
    "        B, L, H, E = queries.shape\n",
    "        _, S, _, D = values.shape\n",
    "        if L > S:\n",
    "            zeros = torch.zeros_like(queries[:, :(L - S), :]).float()\n",
    "            values = torch.cat([values, zeros], dim=1)\n",
    "            keys = torch.cat([keys, zeros], dim=1)\n",
    "        else:\n",
    "            values = values[:, :L, :, :]\n",
    "            keys = keys[:, :L, :, :]\n",
    "\n",
    "        # period-based dependencies\n",
    "        q_fft = torch.fft.rfft(queries.permute(0, 2, 3, 1).contiguous(), dim=-1)\n",
    "        k_fft = torch.fft.rfft(keys.permute(0, 2, 3, 1).contiguous(), dim=-1)\n",
    "        res = q_fft * torch.conj(k_fft)\n",
    "        corr = torch.fft.irfft(res, dim=-1)\n",
    "\n",
    "        # time delay agg\n",
    "        if self.training:\n",
    "            V = self.time_delay_agg_training(values.permute(0, 2, 3, 1).contiguous(), corr).permute(0, 3, 1, 2)\n",
    "        else:\n",
    "            V = self.time_delay_agg_inference(values.permute(0, 2, 3, 1).contiguous(), corr).permute(0, 3, 1, 2)\n",
    "\n",
    "        if self.output_attention:\n",
    "            return (V.contiguous(), corr.permute(0, 3, 1, 2))\n",
    "        else:\n",
    "            return (V.contiguous(), None)\n",
    "\n",
    "\n",
    "class AutoCorrelationLayer(nn.Module):\n",
    "    def __init__(self, correlation, d_model, n_heads, d_keys=None,\n",
    "                 d_values=None):\n",
    "        super(AutoCorrelationLayer, self).__init__()\n",
    "\n",
    "        d_keys = d_keys or (d_model // n_heads)\n",
    "        d_values = d_values or (d_model // n_heads)\n",
    "\n",
    "        self.inner_correlation = correlation\n",
    "        self.query_projection = nn.Linear(d_model, d_keys * n_heads)\n",
    "        self.key_projection = nn.Linear(d_model, d_keys * n_heads)\n",
    "        self.value_projection = nn.Linear(d_model, d_values * n_heads)\n",
    "        self.out_projection = nn.Linear(d_values * n_heads, d_model)\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask):\n",
    "        B, L, _ = queries.shape\n",
    "        _, S, _ = keys.shape\n",
    "        H = self.n_heads\n",
    "\n",
    "        queries = self.query_projection(queries).view(B, L, H, -1)\n",
    "        keys = self.key_projection(keys).view(B, S, H, -1)\n",
    "        values = self.value_projection(values).view(B, S, H, -1)\n",
    "\n",
    "        out, attn = self.inner_correlation(\n",
    "            queries,\n",
    "            keys,\n",
    "            values,\n",
    "            attn_mask\n",
    "        )\n",
    "        out = out.view(B, L, -1)\n",
    "\n",
    "        return self.out_projection(out), attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "11ddc263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univaraite case\n",
    "#   --features S \\\n",
    "#   --seq_len 96 \\\n",
    "#   --label_len 96 \\\n",
    "#   --pred_len 192 \\\n",
    "#   --e_layers 2 \\\n",
    "#   --d_layers 1 \\\n",
    "#   --factor 3 \\\n",
    "#   --enc_in 1 \\\n",
    "#   --dec_in 1 \\\n",
    "#   --c_out 1 \\\n",
    "#   --des 'Exp' \\\n",
    "#   --itr 1 \\\n",
    "#   --freq 't' \\\n",
    "#   --train_epochs 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "b8d95516",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Model(nn.Module):\n",
    "    \"\"\"\n",
    "    Autoformer is the first method to achieve the series-wise connection,\n",
    "    with inherent O(LlogL) complexity\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.seq_len = 96\n",
    "        self.label_len = 96\n",
    "        self.pred_len = 192\n",
    "        self.output_attention = True\n",
    "\n",
    "        # Decomp\n",
    "        self.e_layers = 2\n",
    "        self.d_layers = 1\n",
    "        self.factor = 3\n",
    "        self.kernel_size = 25\n",
    "        self.moving_avg  = 25\n",
    "        self.activation = 'gelu'\n",
    "        self.decomp = series_decomp(self.kernel_size)\n",
    "        self.dropout = 0.05\n",
    "        self.enc_in = 1\n",
    "        self.dec_in = 1\n",
    "        self.freq = 't'\n",
    "        self.embed = 'timeF'\n",
    "        self.d_model = 512\n",
    "        self.n_heads = 8\n",
    "        self.c_out = 1\n",
    "        self.d_ff = 2048\n",
    "#         self.decomp = series_decomp(kernel_size)\n",
    "\n",
    "        # Embedding\n",
    "        # The series-wise connection inherently contains the sequential information.\n",
    "        # Thus, we can discard the position embedding of transformers.\n",
    "        self.enc_embedding = DataEmbedding_wo_pos(self.enc_in, self.d_model, self.embed, self.freq,\n",
    "                                                  self.dropout)\n",
    "        self.dec_embedding = DataEmbedding_wo_pos(self.dec_in, self.d_model, self.embed, self.freq,\n",
    "                                                  self.dropout)\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = Encoder(\n",
    "            [\n",
    "                EncoderLayer(\n",
    "                    AutoCorrelationLayer(\n",
    "                        AutoCorrelation(False, self.factor, attention_dropout=self.dropout,\n",
    "                                        output_attention=self.output_attention),\n",
    "                        self.d_model, self.n_heads),\n",
    "                    self.d_model,\n",
    "                    self.d_ff,\n",
    "                    moving_avg=self.moving_avg,\n",
    "                    dropout=self.dropout,\n",
    "                    activation=self.activation\n",
    "                ) for l in range(self.e_layers)\n",
    "            ],\n",
    "            norm_layer=my_Layernorm(self.d_model)\n",
    "        )\n",
    "        # Decoder\n",
    "        self.decoder = Decoder(\n",
    "            [\n",
    "                DecoderLayer(\n",
    "                    AutoCorrelationLayer(\n",
    "                        AutoCorrelation(True, self.factor, attention_dropout=self.dropout,\n",
    "                                        output_attention=False),\n",
    "                        self.d_model, self.n_heads),\n",
    "                    AutoCorrelationLayer(\n",
    "                        AutoCorrelation(False, self.factor, attention_dropout=self.dropout,\n",
    "                                        output_attention=False),\n",
    "                        self.d_model, self.n_heads),\n",
    "                    self.d_model,\n",
    "                    self.c_out,\n",
    "                    self.d_ff,\n",
    "                    moving_avg=self.moving_avg,\n",
    "                    dropout=self.dropout,\n",
    "                    activation=self.activation,\n",
    "                )\n",
    "                for l in range(self.d_layers)\n",
    "            ],\n",
    "            norm_layer=my_Layernorm(self.d_model),\n",
    "            projection=nn.Linear(self.d_model, self.c_out, bias=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec,\n",
    "                enc_self_mask=None, dec_self_mask=None, dec_enc_mask=None):\n",
    "        # decomp init\n",
    "        mean = torch.mean(x_enc, dim=1).unsqueeze(1).repeat(1, self.pred_len, 1)\n",
    "        zeros = torch.zeros([x_dec.shape[0], self.pred_len, x_dec.shape[2]], device=x_enc.device)\n",
    "        seasonal_init, trend_init = self.decomp(x_enc)\n",
    "        # decoder input\n",
    "        trend_init = torch.cat([trend_init[:, -self.label_len:, :], mean], dim=1)\n",
    "        seasonal_init = torch.cat([seasonal_init[:, -self.label_len:, :], zeros], dim=1)\n",
    "        # enc\n",
    "        enc_out = self.enc_embedding(x_enc.float(), x_mark_enc.float())\n",
    "        enc_out, attns = self.encoder(enc_out, attn_mask=enc_self_mask)\n",
    "        # dec\n",
    "        dec_out = self.dec_embedding(seasonal_init.float(), x_mark_dec.float())\n",
    "        seasonal_part, trend_part = self.decoder(dec_out, enc_out, x_mask=dec_self_mask, cross_mask=dec_enc_mask,\n",
    "                                                 trend=trend_init)\n",
    "        # final\n",
    "        dec_out = trend_part + seasonal_part\n",
    "\n",
    "        if self.output_attention:\n",
    "            return dec_out[:, -self.pred_len:, :], attns\n",
    "        else:\n",
    "            return dec_out[:, -self.pred_len:, :]  # [B, L, D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "55354877",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ED = elc\n",
    "\n",
    "    \n",
    "ED['d'] = pd.to_datetime(ED['date'])\n",
    "ED['Year'] = ED['date'].apply(lambda x: int(x[:10][:4]))\n",
    "ED['month'] = ED['date'].apply(lambda x: int(x[:10][5:7]))\n",
    "ED['hr'] = ED['date'].apply(lambda x: int(x[11:][:2]))\n",
    "ED['min'] = ED['date'].apply(lambda x: int(x[11:][3:5]))\n",
    "ED['day'] = ED.d.apply(lambda row: row.day, 1)\n",
    "ED['weekday'] = ED.d.apply(lambda row: row.weekday(), 1)\n",
    "\n",
    "ED['t'] = ED['Year'] + ((ED['month'] - 1)/ 12) + ((ED['day'] - 1)/ (12 *31) + ED['hr']/(24*31*12) + ED['min']/(60*24*31*12))\n",
    "t = np.array(ED['t'])\n",
    "ED_13 = (ED.loc[ED.t >= 2013, :])\n",
    "\n",
    "client_w_time = (ED.loc[ED.t >= 2013, ['Year', 'month', 'day', 'weekday', 'hr','min', 'OT']])\n",
    "time_feat = ED.loc[ED.t >= 2013, ['Year', 'month', 'day', 'weekday', 'hr','min']]\n",
    "\n",
    "\n",
    "t_13 = ED_13.index\n",
    "train_last_ix = int(len(t_13) *0.8)\n",
    "# target = ED_13.loc[:, ['HUFL','HULL','LUFL','LULL','MUFL', 'MULL', 'OT']]\n",
    "target = ED_13.loc[:, ['OT']]\n",
    "arr_kwh = target \n",
    "_arr =  np.mean(arr_kwh[:train_last_ix], axis=0)\n",
    "_arr =  np.std(arr_kwh[:train_last_ix], axis=0)\n",
    "arr_kwh_a = np.array((arr_kwh - _arr)/_arr)\n",
    "# time_features = client_w_time.iloc[:, 1:6]\n",
    "time_features = client_w_time.iloc[:, 1:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "499f354f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_target = arr_kwh_a[:int(0.7*arr_kwh_a.shape[0])]\n",
    "val_data_target = arr_kwh_a[int(0.7*arr_kwh_a.shape[0]):int(0.8*arr_kwh_a.shape[0])]\n",
    "test_data_target = arr_kwh_a[int(0.8*arr_kwh_a.shape[0]):]\n",
    "\n",
    "\n",
    "training_data_time = time_features.iloc[:int(0.7*arr_kwh_a.shape[0]), :]\n",
    "val_data_time = time_features.iloc[int(0.7*arr_kwh_a.shape[0]):int(0.8*arr_kwh_a.shape[0]), :]\n",
    "test_data_time = time_features.iloc[int(0.8*arr_kwh_a.shape[0]):, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "22a9482d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batcher(time_features, target, batch_s = 32, training=True, tar_dim = 1):\n",
    "    enc_l = 96\n",
    "    dec_l = 192\n",
    "    win_l = enc_l + dec_l\n",
    "    idx = np.random.choice(np.arange(win_l, len(target) - win_l), batch_s)\n",
    "    tar = np.array([target[i:i+win_l] for i in idx])\n",
    "    t = np.array([np.array(time_features)[i:i+win_l, :] for i in idx])    \n",
    "    x_enc = tar[:, :enc_l].reshape(batch_s, enc_l, tar_dim); \n",
    "    x_dec = tar[:, :win_l].reshape(batch_s, win_l, tar_dim)\n",
    "    \n",
    "    y_tar = x_dec[:, -192:, :].copy()\n",
    "    x_dec[:, -192:, :] = 0\n",
    "    \n",
    "    x_mark_enc = t[:, :enc_l, :]; \n",
    "    x_mark_dec = t[:, :win_l, :]\n",
    "    \n",
    "    return x_enc, x_dec, x_mark_enc, x_mark_dec, y_tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "b772a06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "761b0c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "79d1f62f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [327]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m model_optim\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# decoder input\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_x_mark\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_tar\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_y_mark\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m outputs \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m][:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m192\u001b[39m:, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     22\u001b[0m batch_y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(y_tar[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m192\u001b[39m:, \u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_m1_n/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [305]\u001b[0m, in \u001b[0;36mModel.forward\u001b[0;34m(self, x_enc, x_mark_enc, x_dec, x_mark_dec, enc_self_mask, dec_self_mask, dec_enc_mask)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# dec\u001b[39;00m\n\u001b[1;32m     95\u001b[0m dec_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdec_embedding(seasonal_init\u001b[38;5;241m.\u001b[39mfloat(), x_mark_dec\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[0;32m---> 96\u001b[0m seasonal_part, trend_part \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdec_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdec_self_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcross_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdec_enc_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mtrend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrend_init\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# final\u001b[39;00m\n\u001b[1;32m     99\u001b[0m dec_out \u001b[38;5;241m=\u001b[39m trend_part \u001b[38;5;241m+\u001b[39m seasonal_part\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_m1_n/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [300]\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[0;34m(self, x, cross, x_mask, cross_mask, trend)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, cross, x_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, cross_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, trend\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 165\u001b[0m         x, residual_trend \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcross\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcross_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m         trend \u001b[38;5;241m=\u001b[39m trend \u001b[38;5;241m+\u001b[39m residual_trend\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_m1_n/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [300]\u001b[0m, in \u001b[0;36mDecoderLayer.forward\u001b[0;34m(self, x, cross, x_mask, cross_mask)\u001b[0m\n\u001b[1;32m    142\u001b[0m x, trend2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecomp2(x)\n\u001b[1;32m    143\u001b[0m y \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m--> 144\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m    145\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(y)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    146\u001b[0m x, trend3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecomp3(x \u001b[38;5;241m+\u001b[39m y)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_m1_n/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_m1_n/lib/python3.8/site-packages/torch/nn/modules/conv.py:313\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_m1_n/lib/python3.8/site-packages/torch/nn/modules/conv.py:309\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    307\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    308\u001b[0m                     _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 309\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_models = []\n",
    "for j in range(5):\n",
    "    mini = 5000\n",
    "    model = Model()\n",
    "    model_optim = optim.Adam(model.parameters(), lr=0.0001)\n",
    "    criterion = nn.MSELoss()\n",
    "    iter_count = 0\n",
    "    epoch_time = time.time()\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    for i in range(40000):\n",
    "        print(i)\n",
    "        \n",
    "        model.train()\n",
    "        batch_x, batch_y, batch_x_mark, batch_y_mark, y_tar = batcher(np.array(training_data_time), training_data_target) \n",
    "        iter_count += 1\n",
    "        model_optim.zero_grad()\n",
    "        # decoder input\n",
    "        outputs = model(torch.tensor(batch_x), torch.tensor(batch_x_mark), torch.tensor(y_tar), torch.tensor(batch_y_mark))\n",
    "\n",
    "        outputs = outputs[0][:, -192:, 0]\n",
    "        batch_y = torch.tensor(y_tar[:, -192:, 0])\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        loss.backward()\n",
    "        model_optim.step()\n",
    "        if (i + 1) % 500 == 0:\n",
    "            # evaluate model:\n",
    "            model.eval()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                batch_x, batch_y, batch_x_mark, batch_y_mark, y_tar = batcher(np.array(val_data_time), val_data_target, batch_s=100, training=False) \n",
    "                out_data = model(torch.tensor(batch_x), torch.tensor(batch_x_mark), torch.tensor(y_tar), torch.tensor(batch_y_mark))\n",
    "                out_data = out_data[0][:, -192:, 0]\n",
    "                batch_y = torch.tensor(y_tar[:, -192:, 0])\n",
    "                loss_v = criterion(out_data, batch_y)\n",
    "                val_loss.append(loss_v.item())\n",
    "                IPython.display.clear_output(wait=True)\n",
    "                plt.plot(train_loss, label = 'train mse')\n",
    "                plt.plot(val_loss, label= 'validation mse')\n",
    "                plt.show()\n",
    "                if loss_v < mini:\n",
    "                    mini = loss_v\n",
    "                    torch.save(model.state_dict(), 'weights/forecasting/ETT/autoformer/96_context_192_pred/192_out_best-model-parameters_{}.pt'.format(j)) # official recommended\n",
    "\n",
    "            print(\"\\titers: {0}, epoch: {1} | loss: {2:.7f}\".format(i + 1, i + 1, loss.item()))\n",
    "            print(\"\\titers: {0}, epoch: {1} | loss val: {2:.7f}\".format(i + 1, i + 1, loss_v.item()))\n",
    "            print(\"iter: {} cost time: {}\".format(iter_count + 1, time.time() - epoch_time))\n",
    "            epoch_time = time.time()\n",
    "    \n",
    "    best_models.append(np.min(val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "e303f01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_size=0\n",
    "for param in model.parameters():\n",
    "    param_size += param.nelement() * param.element_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "4ded33ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42024964"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a12c28d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = np.load('merged_192_out_96_input.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5c7256e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all = np.load('x_all_test_set_electricity_192_out.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04a28038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "96+192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2bc2a3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_to_delete = np.array([33, 46, 54, 71, 82, 105, 166, 188, 200, 201, 218, 229, 269, 289, 302, 330, 429, 450, 491, 492, 495, 498, 519, 521, 549, 561, 595, 602, 613, 619, 622, 663, 678, 708, 725, 745, 817, 866, 868, 870, 890, 911, 916, 925, 926, 945, 974,\n",
    "891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 912, 913, 914, 915, 917, 918, 919, 920, 921, 922, 923, 924, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3452e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = np.delete(merged, rows_to_delete, axis=0)\n",
    "x_all = np.delete(x_all, rows_to_delete, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be548a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_l = 96\n",
    "win_l = 288\n",
    "batch_s = 850"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bfb50e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    x_enc = merged[:, :enc_l, :].reshape(batch_s, enc_l, 1); \n",
    "\n",
    "    x_dec = merged[:, :win_l, :].reshape(batch_s, win_l, 1)\n",
    "    y_tar = merged[:, -192:, :].copy()\n",
    "    x_dec[:, -192:, :] = 0\n",
    "    \n",
    "    x_mark_enc = x_all[:, :enc_l, :]; \n",
    "    x_mark_dec = x_all[:, :win_l, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0435f4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "import math as ma "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edb57ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_lik(y, , log_, =0.001):\n",
    "    pi = torch.tensor(ma.pi)\n",
    "    mse_per_point = torch.square(torch.subtract(y, ))\n",
    "    lik_per_point = (-1 / 2) * (torch.divide(mse_per_point, torch.square(torch.exp(log_)) + )) - 1*torch.log(torch.exp(log_) + )- (1/2)*torch.log(2*pi)\n",
    "    return lik_per_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc09701d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m like_test_loss \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mModel\u001b[49m() \u001b[38;5;66;03m# we do not specify pretrained=True, i.e. do not load default weights\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m192_out_best-model-parameters_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i)))\n\u001b[1;32m      6\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Model' is not defined"
     ]
    }
   ],
   "source": [
    "mse_test_loss = []\n",
    "like_test_loss = []\n",
    "for i in range(5):\n",
    "    model = Model() # we do not specify pretrained=True, i.e. do not load default weights\n",
    "    model.load_state_dict(torch.load('192_out_best-model-parameters_{}.pt'.format(i)))\n",
    "    model.eval()\n",
    "    \n",
    "    \n",
    "    test_batch_s = 100 #need to specify this as it gets changed in the loop below\n",
    "    idx_list = list(range(test_data_time.shape[0] - (192)))\n",
    "    num_batches = len(idx_list)//test_batch_s\n",
    "\n",
    "    for _ in range(num_batches): #### specify correct number of batches for the batcher #####\n",
    "        if(_ == (num_batches-1)): test_batch_s = len(idx_list)        \n",
    "        batch_x, batch_y, batch_x_mark, batch_y_mark, y_tar = batcher_test(np.array(test_data_time), test_data_target, batch_s=100, training=False) \n",
    "        outputs_te = model(torch.tensor(x_enc), torch.tensor(x_mark_enc), torch.tensor(y_tar), torch.tensor(x_mark_dec))\n",
    "        batch_y = torch.tensor(y_tar)\n",
    "        loss = criterion(outputs_te[0], batch_y)\n",
    "        \n",
    "        _, sum_mse, sum_nll, _, _ = losses.nll(y_te[:, n_C:n_C+n_T], , log_)\n",
    "        sum_nll_tot += sum_nll / n_T\n",
    "        sum_mse_tot += sum_mse / n_T\n",
    "\n",
    "    nllx =  sum_nll_tot / (test_batch_s * x_test.shape[0]//test_batch_s)\n",
    "    msex =  sum_mse_tot / (test_batch_s * x_test.shape[0]//test_batch_s)\n",
    "\n",
    "\n",
    "    nll_list.append(nllx.numpy())\n",
    "    mse_list.append(msex.numpy())\n",
    "                \n",
    "            \n",
    "    np.save(save_dir + '/nll_list.npy', nll_list)    \n",
    "    np.save(save_dir + '/mse_list.npy', mse_list)  \n",
    "\n",
    "    mse_test_loss.append(loss.detach().numpy())\n",
    "    log_ = np.log(np.sqrt(mse_test_loss[-1]))\n",
    "    lik_pp = seq_lik(batch_y, outputs_te[0], torch.tensor(log_))\n",
    "    like_test_loss.append(np.mean(lik_pp.detach().numpy()))\n",
    "print(np.mean(mse_test_loss))\n",
    "print(np.std(mse_test_loss))\n",
    "print(np.mean(like_test_loss))\n",
    "print(np.std(like_test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2b1f2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f3c58c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "543b19cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1., 5., 7., 12.], [63., 15., 52., 172.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4049f2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc1c3a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f845512a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Max\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-07 09:56:17.748194: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-05-07 09:56:17.748356: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4), dtype=float64, numpy=\n",
       "array([[ 12.,   7.,   1.,   5.],\n",
       "       [172.,  52.,  63.,  15.]])>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.transpose(tf.random.shuffle(tf.transpose(a, perm=[1, 0])), perm =[1, 0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51d390b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_wrangler import feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cc88343",
   "metadata": {},
   "outputs": [],
   "source": [
    "f  =feature_extractor.feature_wrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c888537c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=2.0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(2, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adb8146f",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Index out of range using input dim 2; input has only 2 dims [Op:StridedSlice] name: strided_slice/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ATP/data_wrangler/feature_extractor.py:55\u001b[0m, in \u001b[0;36mfeature_wrapper.permute\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x,  y\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \n\u001b[1;32m     50\u001b[0m     \u001b[38;5;66;03m# batch_s = tf.shape(x)[0]\u001b[39;00m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;66;03m# repeated_x = tf.tile(x,  multiples=[num_permutation_repeats, 1, 1])\u001b[39;00m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;66;03m# repeated_y = tf.tile(y,  multiples=[num_permutation_repeats, 1, 1])\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \n\u001b[1;32m     54\u001b[0m     \u001b[38;5;66;03m#Shuffle traget only. tf.random.shuffle only works on the first dimension so we need tf.transpose.\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m     x_permuted \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconcat([tf\u001b[38;5;241m.\u001b[39mconcat([x[:,  :n_C, :], tf\u001b[38;5;241m.\u001b[39mtranspose(tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mshuffle(tf\u001b[38;5;241m.\u001b[39mtranspose(x[:, n_C:, :], perm\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m])), perm \u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m])], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_permutation_repeats)], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)            \n\u001b[1;32m     56\u001b[0m     y_permuted \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconcat([tf\u001b[38;5;241m.\u001b[39mconcat([y[:,  :n_C, :], tf\u001b[38;5;241m.\u001b[39mtranspose(tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mshuffle(tf\u001b[38;5;241m.\u001b[39mtranspose(y[:, n_C:, :], perm\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m])), perm \u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m])], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_permutation_repeats)], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;66;03m# x_permuted = tf.concat([repeated_x[:,  :n_C, :],  x_target],  axis=1)\u001b[39;00m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# y_permuted = tf.concat([repeated_y[:,  :n_C, :],  y_target],  axis=1)\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/ATP/data_wrangler/feature_extractor.py:55\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x,  y\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \n\u001b[1;32m     50\u001b[0m     \u001b[38;5;66;03m# batch_s = tf.shape(x)[0]\u001b[39;00m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;66;03m# repeated_x = tf.tile(x,  multiples=[num_permutation_repeats, 1, 1])\u001b[39;00m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;66;03m# repeated_y = tf.tile(y,  multiples=[num_permutation_repeats, 1, 1])\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \n\u001b[1;32m     54\u001b[0m     \u001b[38;5;66;03m#Shuffle traget only. tf.random.shuffle only works on the first dimension so we need tf.transpose.\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m     x_permuted \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconcat([tf\u001b[38;5;241m.\u001b[39mconcat([\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43m:\u001b[49m\u001b[43mn_C\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m, tf\u001b[38;5;241m.\u001b[39mtranspose(tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mshuffle(tf\u001b[38;5;241m.\u001b[39mtranspose(x[:, n_C:, :], perm\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m])), perm \u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m])], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_permutation_repeats)], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)            \n\u001b[1;32m     56\u001b[0m     y_permuted \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconcat([tf\u001b[38;5;241m.\u001b[39mconcat([y[:,  :n_C, :], tf\u001b[38;5;241m.\u001b[39mtranspose(tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mshuffle(tf\u001b[38;5;241m.\u001b[39mtranspose(y[:, n_C:, :], perm\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m])), perm \u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m])], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_permutation_repeats)], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;66;03m# x_permuted = tf.concat([repeated_x[:,  :n_C, :],  x_target],  axis=1)\u001b[39;00m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# y_permuted = tf.concat([repeated_y[:,  :n_C, :],  y_target],  axis=1)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_m1_n/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_m1_n/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:7186\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7185\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 7186\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Index out of range using input dim 2; input has only 2 dims [Op:StridedSlice] name: strided_slice/"
     ]
    }
   ],
   "source": [
    "f.permute([tf.constant(a, dtype=tf.float32), tf.constant(b, dtype=tf.float32), tf.constant(2, dtype=tf.int32), tf.constant(2, dtype=tf.int32), tf.constant(2, dtype=tf.int32)])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14954266",
   "metadata": {},
   "outputs": [],
   "source": [
    "from comparison_models.gru import gru_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e807b4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gru_pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m g1 \u001b[38;5;241m=\u001b[39m  \u001b[43mgru_pipeline\u001b[49m\u001b[38;5;241m.\u001b[39mgru_pipeline([\u001b[38;5;241m10\u001b[39m], \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gru_pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "g1 =  gru_pipeline.gru_pipeline([10], 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6e44a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_wrangler import dataset_preparer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "788e0ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "        x_train, y_train, x_val, y_val, x_test, y_test = dataset_preparer.weather_processor(path_to_weather_data=\"datasets/weather.csv\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fb5b630",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_wrangler import batcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c164d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_C = 10\n",
    "n_T = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46149efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "            idx_list = list(range(x_train.shape[0] - (n_C+n_T)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b439b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,_ = batcher.batcher(x_train,y_train,idx_list,window=n_C+n_T) ####### generalise for not just forecasting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "316161f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 20, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a355af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = f.permute([x,y, 10, 10, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5bd5fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
       "array([0.45411626, 0.46649173, 0.45411626, 0.39687976, 0.40770826,\n",
       "       0.45102248, 0.46958566, 0.50516504, 0.5330099 , 0.5438383 ,\n",
       "       0.6644992 , 0.5639485 , 0.5670424 , 0.6644992 , 0.56549543,\n",
       "       0.67223376, 0.6119035 , 0.68770313, 0.63974816, 0.5902464 ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0 , :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90ed2617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
       "array([0.45411626, 0.46649173, 0.45411626, 0.39687976, 0.40770826,\n",
       "       0.45102248, 0.46958566, 0.50516504, 0.5330099 , 0.5438383 ,\n",
       "       0.6119035 , 0.5902464 , 0.63974816, 0.56549543, 0.5639485 ,\n",
       "       0.5670424 , 0.68770313, 0.6644992 , 0.6644992 , 0.67223376],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[32, : , 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6925abfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
       "array([[0.01103164],\n",
       "       [0.01750057],\n",
       "       [0.01374215],\n",
       "       [0.01171413],\n",
       "       [0.01860397],\n",
       "       [0.02116016],\n",
       "       [0.01885492],\n",
       "       [0.02241357],\n",
       "       [0.02199049],\n",
       "       [0.01917847]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0, : ,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e81c6dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
       "array([[-0.2153583 ],\n",
       "       [-0.20701684],\n",
       "       [-0.2052439 ],\n",
       "       [-0.20571813],\n",
       "       [-0.21017832],\n",
       "       [-0.20565562],\n",
       "       [-0.21185149],\n",
       "       [-0.20508847],\n",
       "       [-0.20309193],\n",
       "       [-0.20570324]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[32, : ,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c2f1bd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_C =10\n",
    "n_T =15\n",
    "batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8fe55322",
   "metadata": {},
   "outputs": [],
   "source": [
    "        x_mask = tf.linalg.band_part(tf.ones((n_T, n_C + n_T), tf.bool), -1, n_C)\n",
    "        x_mask_inv = (x_mask == False)\n",
    "        x_mask_float = tf.cast(x_mask_inv, \"float32\")*1000\n",
    "        x_mask_float_repeat = tf.repeat(x_mask_float[tf.newaxis, :], axis=0, repeats=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "593708c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "        x_mask = 1000  * (tf.constant(1, tf.int32) -  tf.linalg.band_part(tf.ones((n_T, n_C + n_T), tf.int32), -1, n_C))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9ee36c36",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0., 1000., 1000., 1000., 1000., 1000., 1000., 1000.,\n",
       "        1000., 1000., 1000., 1000., 1000., 1000., 1000.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0., 1000., 1000., 1000., 1000., 1000., 1000.,\n",
       "        1000., 1000., 1000., 1000., 1000., 1000., 1000.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0., 1000., 1000., 1000., 1000., 1000.,\n",
       "        1000., 1000., 1000., 1000., 1000., 1000., 1000.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0., 1000., 1000., 1000., 1000.,\n",
       "        1000., 1000., 1000., 1000., 1000., 1000., 1000.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0., 1000., 1000., 1000.,\n",
       "        1000., 1000., 1000., 1000., 1000., 1000., 1000.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0., 1000., 1000.,\n",
       "        1000., 1000., 1000., 1000., 1000., 1000., 1000.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0., 1000.,\n",
       "        1000., 1000., 1000., 1000., 1000., 1000., 1000.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "        1000., 1000., 1000., 1000., 1000., 1000., 1000.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0., 1000., 1000., 1000., 1000., 1000., 1000.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0., 1000., 1000., 1000., 1000., 1000.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0., 1000., 1000., 1000., 1000.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0., 1000., 1000., 1000.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0., 1000., 1000.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0., 1000.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_mask_float.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "82151545",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True, False, False, False, False, False, False, False,\n",
       "        False, False],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True, False, False, False, False, False, False,\n",
       "        False, False],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True, False, False, False, False, False,\n",
       "        False, False],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True, False, False, False, False,\n",
       "        False, False],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True, False, False, False,\n",
       "        False, False],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "        False, False],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        False, False],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        False, False],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True, False],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_mask.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a2f3ce33",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 10, 20), dtype=float32, numpy=\n",
       "array([[[   0.,    0.,    0., ..., 1000., 1000., 1000.],\n",
       "        [   0.,    0.,    0., ..., 1000., 1000., 1000.],\n",
       "        [   0.,    0.,    0., ..., 1000., 1000., 1000.],\n",
       "        ...,\n",
       "        [   0.,    0.,    0., ...,    0., 1000., 1000.],\n",
       "        [   0.,    0.,    0., ...,    0.,    0., 1000.],\n",
       "        [   0.,    0.,    0., ...,    0.,    0.,    0.]],\n",
       "\n",
       "       [[   0.,    0.,    0., ..., 1000., 1000., 1000.],\n",
       "        [   0.,    0.,    0., ..., 1000., 1000., 1000.],\n",
       "        [   0.,    0.,    0., ..., 1000., 1000., 1000.],\n",
       "        ...,\n",
       "        [   0.,    0.,    0., ...,    0., 1000., 1000.],\n",
       "        [   0.,    0.,    0., ...,    0.,    0., 1000.],\n",
       "        [   0.,    0.,    0., ...,    0.,    0.,    0.]],\n",
       "\n",
       "       [[   0.,    0.,    0., ..., 1000., 1000., 1000.],\n",
       "        [   0.,    0.,    0., ..., 1000., 1000., 1000.],\n",
       "        [   0.,    0.,    0., ..., 1000., 1000., 1000.],\n",
       "        ...,\n",
       "        [   0.,    0.,    0., ...,    0., 1000., 1000.],\n",
       "        [   0.,    0.,    0., ...,    0.,    0., 1000.],\n",
       "        [   0.,    0.,    0., ...,    0.,    0.,    0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[   0.,    0.,    0., ..., 1000., 1000., 1000.],\n",
       "        [   0.,    0.,    0., ..., 1000., 1000., 1000.],\n",
       "        [   0.,    0.,    0., ..., 1000., 1000., 1000.],\n",
       "        ...,\n",
       "        [   0.,    0.,    0., ...,    0., 1000., 1000.],\n",
       "        [   0.,    0.,    0., ...,    0.,    0., 1000.],\n",
       "        [   0.,    0.,    0., ...,    0.,    0.,    0.]],\n",
       "\n",
       "       [[   0.,    0.,    0., ..., 1000., 1000., 1000.],\n",
       "        [   0.,    0.,    0., ..., 1000., 1000., 1000.],\n",
       "        [   0.,    0.,    0., ..., 1000., 1000., 1000.],\n",
       "        ...,\n",
       "        [   0.,    0.,    0., ...,    0., 1000., 1000.],\n",
       "        [   0.,    0.,    0., ...,    0.,    0., 1000.],\n",
       "        [   0.,    0.,    0., ...,    0.,    0.,    0.]],\n",
       "\n",
       "       [[   0.,    0.,    0., ..., 1000., 1000., 1000.],\n",
       "        [   0.,    0.,    0., ..., 1000., 1000., 1000.],\n",
       "        [   0.,    0.,    0., ..., 1000., 1000., 1000.],\n",
       "        ...,\n",
       "        [   0.,    0.,    0., ...,    0., 1000., 1000.],\n",
       "        [   0.,    0.,    0., ...,    0.,    0., 1000.],\n",
       "        [   0.,    0.,    0., ...,    0.,    0.,    0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_mask_float_repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a512d2c6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 20), dtype=float32, numpy=\n",
       "array([[   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0., 1000., 1000., 1000., 1000., 1000., 1000., 1000.,\n",
       "        1000., 1000.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0., 1000., 1000., 1000., 1000., 1000., 1000.,\n",
       "        1000., 1000.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0., 1000., 1000., 1000., 1000., 1000.,\n",
       "        1000., 1000.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0., 1000., 1000., 1000., 1000.,\n",
       "        1000., 1000.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0., 1000., 1000., 1000.,\n",
       "        1000., 1000.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0., 1000., 1000.,\n",
       "        1000., 1000.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0., 1000.,\n",
       "        1000., 1000.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "        1000., 1000.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0., 1000.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.]], dtype=float32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_mask_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2df138a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 20), dtype=bool, numpy=\n",
       "array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True, False, False, False, False, False, False, False,\n",
       "        False, False],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True, False, False, False, False, False, False,\n",
       "        False, False],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True, False, False, False, False, False,\n",
       "        False, False],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True, False, False, False, False,\n",
       "        False, False],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True, False, False, False,\n",
       "        False, False],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "        False, False],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        False, False],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        False, False],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True, False],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True]])>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba653284",
   "metadata": {},
   "outputs": [],
   "source": [
    "    mask = np.tri(n_C + n_T, n_C + n_T, 0) - np.eye(n_C + n_T)\n",
    "    mask[:n_C, :n_C] = 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a71b3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TNP mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fa204687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [1., 1., 0., 0., 0.],\n",
       "       [1., 1., 1., 0., 0.],\n",
       "       [1., 1., 1., 1., 0.],\n",
       "       [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tri(n_C + n_T, n_C + n_T, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f198bf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.normal(size=(5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e6fb335c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 5), dtype=float32, numpy=\n",
       "array([[1., 0., 0., 0., 0.],\n",
       "       [1., 1., 0., 0., 0.],\n",
       "       [1., 1., 1., 0., 0.],\n",
       "       [1., 1., 1., 1., 0.],\n",
       "       [1., 1., 1., 1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.linalg.band_part(tf.ones([n_C + n_T, n_C + n_T]), -1, 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "448bc028",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'tri'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m mask_a \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtri\u001b[49m(n_C \u001b[38;5;241m+\u001b[39m n_T, n_C \u001b[38;5;241m+\u001b[39m n_T, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m tf\u001b[38;5;241m.\u001b[39meye(n_C \u001b[38;5;241m+\u001b[39m n_T)\n\u001b[1;32m      2\u001b[0m mask_a[:n_C, :n_C] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'tri'"
     ]
    }
   ],
   "source": [
    "    mask_a = tf.tri(n_C + n_T, n_C + n_T, 0) - tf.eye(n_C + n_T)\n",
    "    mask_a[:n_C, :n_C] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7137e071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 5), dtype=float64, numpy=\n",
       "array([[1., 1., 0., 0., 0.],\n",
       "       [1., 1., 0., 0., 0.],\n",
       "       [1., 1., 0., 0., 0.],\n",
       "       [1., 1., 1., 0., 0.],\n",
       "       [1., 1., 1., 1., 0.],\n",
       "       [1., 1., 0., 0., 0.],\n",
       "       [1., 1., 0., 0., 0.],\n",
       "       [1., 1., 0., 0., 0.],\n",
       "       [1., 1., 1., 0., 0.],\n",
       "       [1., 1., 1., 1., 0.]])>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.concat([mask_a , mask_a], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b5b0179",
   "metadata": {},
   "outputs": [],
   "source": [
    "        context_part = tf.concat([tf.ones((n_C,n_C),tf.bool),tf.zeros((n_C,2*n_T),tf.bool)],\n",
    "                         axis=-1)\n",
    "        first_part = tf.linalg.band_part(tf.ones((n_T,n_C+2*n_T),tf.bool),-1,n_C)\n",
    "        second_part = tf.linalg.band_part(tf.ones((n_T,n_C+2*n_T),tf.bool),-1,n_C-1)\n",
    "        mask = tf.concat([context_part,first_part,second_part],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a14994e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8, 8), dtype=bool, numpy=\n",
       "array([[ True,  True, False, False, False, False, False, False],\n",
       "       [ True,  True, False, False, False, False, False, False],\n",
       "       [ True,  True,  True, False, False, False, False, False],\n",
       "       [ True,  True,  True,  True, False, False, False, False],\n",
       "       [ True,  True,  True,  True,  True, False, False, False],\n",
       "       [ True,  True, False, False, False, False, False, False],\n",
       "       [ True,  True,  True, False, False, False, False, False],\n",
       "       [ True,  True,  True,  True, False, False, False, False]])>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b848396",
   "metadata": {},
   "outputs": [],
   "source": [
    "######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87712871",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf3c134",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6069a4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de663f48",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 0.]],\n",
       "\n",
       "       [[1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 0.]],\n",
       "\n",
       "       [[1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 0.]],\n",
       "\n",
       "       [[1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 0.]],\n",
       "\n",
       "       [[1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 0.]],\n",
       "\n",
       "       [[1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 0.]],\n",
       "\n",
       "       [[1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 0.]],\n",
       "\n",
       "       [[1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 0.]],\n",
       "\n",
       "       [[1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 0.]],\n",
       "\n",
       "       [[1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 0.]],\n",
       "\n",
       "       [[1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 0.]],\n",
       "\n",
       "       [[1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 0.]],\n",
       "\n",
       "       [[1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 0.]],\n",
       "\n",
       "       [[1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 0.]],\n",
       "\n",
       "       [[1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 0.]],\n",
       "\n",
       "       [[1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 0.]],\n",
       "\n",
       "       [[1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 0.]],\n",
       "\n",
       "       [[1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 0.]],\n",
       "\n",
       "       [[1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 0.]],\n",
       "\n",
       "       [[1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 0.]],\n",
       "\n",
       "       [[1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 0.]],\n",
       "\n",
       "       [[1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 0.]],\n",
       "\n",
       "       [[1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 0.]],\n",
       "\n",
       "       [[1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 0.]],\n",
       "\n",
       "       [[1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 0.]],\n",
       "\n",
       "       [[1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 0.]],\n",
       "\n",
       "       [[1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 0.]],\n",
       "\n",
       "       [[1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 0.]],\n",
       "\n",
       "       [[1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 0.]],\n",
       "\n",
       "       [[1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 0.]],\n",
       "\n",
       "       [[1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 0.]],\n",
       "\n",
       "       [[1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 0.]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1ec70ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "        y_temp = tf.squeeze(y[:, :n_C])\n",
    "        y_temp = tf.repeat(tf.expand_dims(y_temp,  axis=1),  axis=1,  repeats=n_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5d7a6588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 10, 10, 1])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fa6d713",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_C = 2\n",
    "n_T = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbeb3243",
   "metadata": {},
   "outputs": [],
   "source": [
    "        context_part = tf.concat([tf.ones((n_C,n_C),tf.bool),tf.zeros((n_C,n_T),tf.bool)],axis=-1)\n",
    "        diagonal_mask = tf.linalg.band_part(tf.ones((n_C+n_T,n_C+n_T),tf.bool),-1,0)\n",
    "        lower_diagonal_mask = tf.linalg.set_diag(diagonal_mask,tf.zeros(diagonal_mask.shape[0:-1],tf.bool)) ### condense into one line?                                                                               \n",
    "        mask = tf.concat([context_part,lower_diagonal_mask[n_C:n_C+n_T,:n_C+n_T]],axis=0) # check no conflicts with init and check mask is correct shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a34c2fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 5), dtype=bool, numpy=\n",
       "array([[ True,  True, False, False, False],\n",
       "       [ True,  True, False, False, False],\n",
       "       [ True,  True, False, False, False],\n",
       "       [ True,  True,  True, False, False],\n",
       "       [ True,  True,  True,  True, False]])>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f140915b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-10.m102",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-10:m102"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
