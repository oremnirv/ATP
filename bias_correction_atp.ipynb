{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b418dfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import atp_graph, losses\n",
    "from data_wrangler import synthetic_data_gen, feature_extractor\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from model import atp_pipeline\n",
    "from comparison_models.tnp import tnp_pipeline\n",
    "from data_wrangler import dataset_preparer\n",
    "import argparse\n",
    "from data_wrangler.batcher import batcher, batcher_np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0476c966",
   "metadata": {},
   "outputs": [],
   "source": [
    "exchange = pd.read_csv('datasets/exchange.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e388e7b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>OT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990/1/1 0:00</td>\n",
       "      <td>0.785500</td>\n",
       "      <td>1.611000</td>\n",
       "      <td>0.861698</td>\n",
       "      <td>0.634196</td>\n",
       "      <td>0.211242</td>\n",
       "      <td>0.006838</td>\n",
       "      <td>0.525486</td>\n",
       "      <td>0.593000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990/1/2 0:00</td>\n",
       "      <td>0.781800</td>\n",
       "      <td>1.610000</td>\n",
       "      <td>0.861104</td>\n",
       "      <td>0.633513</td>\n",
       "      <td>0.211242</td>\n",
       "      <td>0.006863</td>\n",
       "      <td>0.523972</td>\n",
       "      <td>0.594000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990/1/3 0:00</td>\n",
       "      <td>0.786700</td>\n",
       "      <td>1.629300</td>\n",
       "      <td>0.861030</td>\n",
       "      <td>0.648508</td>\n",
       "      <td>0.211242</td>\n",
       "      <td>0.006975</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.597300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1990/1/4 0:00</td>\n",
       "      <td>0.786000</td>\n",
       "      <td>1.637000</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.650618</td>\n",
       "      <td>0.211242</td>\n",
       "      <td>0.006953</td>\n",
       "      <td>0.523834</td>\n",
       "      <td>0.597000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990/1/5 0:00</td>\n",
       "      <td>0.784900</td>\n",
       "      <td>1.653000</td>\n",
       "      <td>0.861995</td>\n",
       "      <td>0.656254</td>\n",
       "      <td>0.211242</td>\n",
       "      <td>0.006940</td>\n",
       "      <td>0.527426</td>\n",
       "      <td>0.598500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7583</th>\n",
       "      <td>2010/10/6 0:00</td>\n",
       "      <td>0.718494</td>\n",
       "      <td>1.222195</td>\n",
       "      <td>0.737485</td>\n",
       "      <td>0.969974</td>\n",
       "      <td>0.143697</td>\n",
       "      <td>0.008500</td>\n",
       "      <td>0.688565</td>\n",
       "      <td>0.690846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7584</th>\n",
       "      <td>2010/10/7 0:00</td>\n",
       "      <td>0.721839</td>\n",
       "      <td>1.223459</td>\n",
       "      <td>0.741155</td>\n",
       "      <td>0.977297</td>\n",
       "      <td>0.143763</td>\n",
       "      <td>0.008595</td>\n",
       "      <td>0.690288</td>\n",
       "      <td>0.695701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7585</th>\n",
       "      <td>2010/10/8 0:00</td>\n",
       "      <td>0.723197</td>\n",
       "      <td>1.234111</td>\n",
       "      <td>0.745184</td>\n",
       "      <td>0.984446</td>\n",
       "      <td>0.143997</td>\n",
       "      <td>0.008562</td>\n",
       "      <td>0.691419</td>\n",
       "      <td>0.695943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7586</th>\n",
       "      <td>2010/10/9 0:00</td>\n",
       "      <td>0.720825</td>\n",
       "      <td>1.233905</td>\n",
       "      <td>0.744131</td>\n",
       "      <td>0.980344</td>\n",
       "      <td>0.143993</td>\n",
       "      <td>0.008555</td>\n",
       "      <td>0.690942</td>\n",
       "      <td>0.692689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7587</th>\n",
       "      <td>2010/10/10 0:00</td>\n",
       "      <td>0.720825</td>\n",
       "      <td>1.233905</td>\n",
       "      <td>0.744131</td>\n",
       "      <td>0.980344</td>\n",
       "      <td>0.143993</td>\n",
       "      <td>0.008555</td>\n",
       "      <td>0.690942</td>\n",
       "      <td>0.692689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7588 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date         0         1         2         3         4  \\\n",
       "0       1990/1/1 0:00  0.785500  1.611000  0.861698  0.634196  0.211242   \n",
       "1       1990/1/2 0:00  0.781800  1.610000  0.861104  0.633513  0.211242   \n",
       "2       1990/1/3 0:00  0.786700  1.629300  0.861030  0.648508  0.211242   \n",
       "3       1990/1/4 0:00  0.786000  1.637000  0.862069  0.650618  0.211242   \n",
       "4       1990/1/5 0:00  0.784900  1.653000  0.861995  0.656254  0.211242   \n",
       "...               ...       ...       ...       ...       ...       ...   \n",
       "7583   2010/10/6 0:00  0.718494  1.222195  0.737485  0.969974  0.143697   \n",
       "7584   2010/10/7 0:00  0.721839  1.223459  0.741155  0.977297  0.143763   \n",
       "7585   2010/10/8 0:00  0.723197  1.234111  0.745184  0.984446  0.143997   \n",
       "7586   2010/10/9 0:00  0.720825  1.233905  0.744131  0.980344  0.143993   \n",
       "7587  2010/10/10 0:00  0.720825  1.233905  0.744131  0.980344  0.143993   \n",
       "\n",
       "             5         6        OT  \n",
       "0     0.006838  0.525486  0.593000  \n",
       "1     0.006863  0.523972  0.594000  \n",
       "2     0.006975  0.526316  0.597300  \n",
       "3     0.006953  0.523834  0.597000  \n",
       "4     0.006940  0.527426  0.598500  \n",
       "...        ...       ...       ...  \n",
       "7583  0.008500  0.688565  0.690846  \n",
       "7584  0.008595  0.690288  0.695701  \n",
       "7585  0.008562  0.691419  0.695943  \n",
       "7586  0.008555  0.690942  0.692689  \n",
       "7587  0.008555  0.690942  0.692689  \n",
       "\n",
       "[7588 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6c1664b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_array[:, 0] = np.linspace(0, 1, len(ex_array[:, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb219bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_array = np.float32(ex_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "63ca513a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batcher_bc(array, n_C, n_T, batch_size=32):\n",
    "    eye_matrix = np.eye(array.shape[1]-1)\n",
    "    y_reordered = []\n",
    "    t_reordered = []\n",
    "    t = []\n",
    "    y = []\n",
    "    for i in range(batch_size):\n",
    "        index = int(np.random.randint(0, array.shape[0] - n_C - n_T, 1))\n",
    "        t_context =  array[index:index + n_C , 0]\n",
    "        t_context = np.repeat(t_context, array.shape[1] - 1)[:, np.newaxis]\n",
    "        t_target = array[index + n_C:index + n_C + n_T, 0]\n",
    "        t_target = np.repeat(t_target, array.shape[1] - 1)[:, np.newaxis]\n",
    "        \n",
    "        y_temp_context = array[index:index + n_C , 1]\n",
    "        y_temp_target = array[index + n_C:index + n_C + n_T, 1]\n",
    "        y_temp_all = np.concatenate([y_temp_context, y_temp_target], axis=0)\n",
    "        t_all = np.repeat(np.concatenate([t_context, t_target], axis=0), array.shape[1] - 1)\n",
    "        \n",
    "        y_temp_context = np.concatenate([y_temp_context[:, np.newaxis], np.repeat(eye_matrix[:, 0][np.newaxis, :], repeats=n_C, axis=0)], axis=1)\n",
    "        y_temp_target = np.concatenate([y_temp_target[:, np.newaxis], np.repeat(eye_matrix[:, 0][np.newaxis, :], repeats=n_T, axis=0)], axis=1)\n",
    "        for i in range(2, array.shape[1]):\n",
    "            y_next_context = np.concatenate([array[index:index + n_C, i][:, np.newaxis], np.repeat(eye_matrix[:, i - 1][np.newaxis, :], repeats=n_C, axis=0)], axis=1)\n",
    "            y_temp_context = np.concatenate([y_temp_context, y_next_context], axis=0)\n",
    "            y_next_target  = np.concatenate([array[index + n_C:index + n_C + n_T, i][:, np.newaxis], np.repeat(eye_matrix[:, i - 1][np.newaxis, :], repeats=n_T, axis=0)], axis=1)\n",
    "            y_temp_target  = np.concatenate([y_temp_target, y_next_target], axis=0)\n",
    "            y_temp_all = np.concatenate([y_temp_all, array[index:index + n_C + n_T, i]], axis=0)\n",
    "\n",
    "\n",
    "        y_temp = np.concatenate([y_temp_context, y_temp_target], axis=0)\n",
    "        y_reordered.append(y_temp)\n",
    "        t_reordered.append(np.concatenate([t_context, t_target], axis=0))\n",
    "        t.append(t_all)\n",
    "        y.append(y_temp_all)\n",
    "    return np.array(y), np.array(y_reordered), np.array(t), np.array(t_reordered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "70fa5637",
   "metadata": {},
   "outputs": [],
   "source": [
    "y, y_reordered, t, t_reordered = batcher_bc(ex_array, 20, 10, 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1ed0636b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 240, 1)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_reordered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6dd6c26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_C = 20\n",
    "n_T = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "85e05be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_C_b  = n_C * (y.shape[-1] - 1)\n",
    "n_T_b = n_T * (y.shape[-1] - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7de8b0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "        context_part = tf.concat([tf.ones((n_C_b,n_C_b),tf.bool),tf.zeros((n_C_b,n_T_b),tf.bool)],axis=-1)\n",
    "        diagonal_mask = tf.linalg.band_part(tf.ones((n_C_b+n_T_b,n_C_b+n_T_b),tf.bool),-1,0)\n",
    "        lower_diagonal_mask = tf.linalg.set_diag(diagonal_mask,tf.zeros(diagonal_mask.shape[0:-1],tf.bool)) ### condense into one line?                                                                               \n",
    "        mask = tf.concat([context_part,lower_diagonal_mask[n_C_b:n_C_b+n_T_b,:n_C_b+n_T_b]],axis=0) # check no conflicts with init and check mask is correct shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b037b0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DE(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.batch_norm_layer = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    def call(self,  inputs):\n",
    "        y,  x,  n_C,  n_T,  training = inputs\n",
    "        print(x.shape)\n",
    "        if (x.shape[-1] == 1):\n",
    "            y_diff,  x_diff,  d,  x_n,  y_n = self.derivative_function([y,  x,  n_C,  n_T])\n",
    "        else: \n",
    "            y_diff,  x_diff,  d,  x_n,  y_n = self.derivative_function_2d([y,  x,  n_C,  n_T])\n",
    "\n",
    "        d_1 = tf.where(tf.math.is_nan(d),  10000.0,  d)\n",
    "        d_2 = tf.where(tf.abs(d) > 200.,  0.,  d)\n",
    "        d = self.batch_norm_layer(d_2,  training=training)\n",
    "\n",
    "        d_label = tf.cast(tf.math.equal(d_2,  d_1),  \"float32\")\n",
    "        d = tf.concat([d,  d_label],  axis=-1)\n",
    "\n",
    "        return y_diff,  x_diff,  d,  x_n,  y_n\n",
    "\n",
    "\n",
    "###### i think here what we do is calculate the derivative at the given y value and add that in as a feature. This is masked when making predictions\n",
    "# so the derivative of other y values are what are seen\n",
    "#  Based on taylor expansion, a better feature would be including the derivative of the closest x point, where only seen y values are used for the differencing. \n",
    "#this derivative wouldn't need masking.\n",
    "\n",
    " ############ check what to do for 2d derivatives - should y diff just be for one point? for residual trick that would make most sense.\n",
    " #### but you need mutli-dimensional y for the derivative\n",
    "\n",
    " ###### and explain why we do this\n",
    "\n",
    "    def derivative_function(self,  inputs, ϵ=0.000002):\n",
    "        ## need to add shape information to inputs\n",
    "        print('please add shape information to inputs')\n",
    "        \n",
    "        y_values,  x_values,  n_C,  n_T = inputs\n",
    "\n",
    "        batch_size = y_values.shape[0]\n",
    "\n",
    "        dim_x = x_values.shape[-1]\n",
    "        dim_y = y_values.shape[-1]\n",
    "\n",
    "\n",
    "        #context section\n",
    "\n",
    "        current_x = tf.expand_dims(x_values[:, :n_C], axis=2)\n",
    "        current_y = tf.expand_dims(y_values[:, :n_C], axis=2)\n",
    "\n",
    "        x_temp = x_values[:, :n_C]\n",
    "        x_temp = tf.repeat(tf.expand_dims(x_temp,  axis=1),  axis=1,  repeats=n_C)\n",
    "\n",
    "        y_temp = y_values[:, :n_C]\n",
    "        y_temp = tf.repeat(tf.expand_dims(y_temp,  axis=1),  axis=1,  repeats=n_C)\n",
    "\n",
    "        ix = tf.argsort(tf.math.reduce_euclidean_norm((current_x - x_temp), axis=-1), axis=-1)[:, :, 1]        \n",
    "        selection_indices = tf.concat([tf.reshape(tf.repeat(tf.range(batch_size*n_C), 1), (-1, 1)), \n",
    "                                       tf.reshape(ix, (-1, 1))], axis=1)\n",
    "\n",
    "\n",
    "        x_closest = tf.reshape(tf.gather_nd(tf.reshape(x_temp, (-1, n_C, dim_x)), selection_indices), \n",
    "                               (batch_size, n_C, dim_x)) \n",
    "        \n",
    "        \n",
    "        y_closest = tf.reshape(tf.gather_nd(tf.reshape(y_temp, (-1, n_C, dim_y)), selection_indices), \n",
    "                       (batch_size, n_C, dim_y))\n",
    "        \n",
    "        x_rep = current_x[:, :, 0] - x_closest\n",
    "        y_rep = current_y[:, :, 0] - y_closest            \n",
    "\n",
    "        deriv = y_rep / (ϵ + tf.math.reduce_euclidean_norm(x_rep, axis=-1, keepdims=True))\n",
    "\n",
    "        dydx_dummy = deriv\n",
    "        diff_y_dummy = y_rep\n",
    "        diff_x_dummy =x_rep\n",
    "        closest_y_dummy = y_closest\n",
    "        closest_x_dummy = x_closest\n",
    "\n",
    "        #target selection\n",
    "\n",
    "        current_x = x_values[:, n_C:n_C+n_T, tf.newaxis]\n",
    "        current_y = y_values[:, n_C:n_C+n_T, tf.newaxis]\n",
    "\n",
    "        x_temp = tf.repeat(x_values[:, :n_T+n_C], axis=1, repeats=n_T)\n",
    "        y_temp = tf.repeat(y_values[:, :n_T+n_C], axis=1, repeats=n_T)\n",
    "\n",
    "\n",
    "        x_mask = tf.linalg.band_part(tf.ones((n_T, n_C + n_T), tf.bool), -1, n_C)\n",
    "        x_mask_inv = (x_mask == False)\n",
    "        x_mask_float = tf.cast(x_mask_inv, \"float32\")*1000\n",
    "        x_mask_float_repeat = tf.repeat(x_mask_float[tf.newaxis, :], axis=0, repeats=batch_size)\n",
    "\n",
    "        print((current_x - x_temp).shape)\n",
    "\n",
    "        # print(x_mask_repeat.shape)\n",
    "        ix = tf.argsort(tf.cast(tf.math.reduce_euclidean_norm((current_x - x_temp), \n",
    "                                            axis=-1), dtype=\"float32\") + x_mask_float_repeat, axis=-1)[:, :, 1]\n",
    "\n",
    "        print(ix.shape)\n",
    "        selection_indices = tf.concat([tf.reshape(tf.repeat(tf.range(batch_size*n_T), 1), (-1, 1)), \n",
    "                                   tf.reshape(ix, (-1, 1))], axis=1)\n",
    "\n",
    "        x_closest = tf.reshape(tf.gather_nd(tf.reshape(x_temp, (-1, n_T+n_C, dim_x)), selection_indices), \n",
    "                               (batch_size, n_T, dim_x)) \n",
    "        \n",
    "        y_closest = tf.reshape(tf.gather_nd(tf.reshape(y_temp, (-1, n_T+n_C, dim_y)), selection_indices), \n",
    "                       (batch_size, n_T, dim_y))\n",
    "        \n",
    "        \n",
    "        x_rep = current_x[:, :, 0] - x_closest\n",
    "        y_rep = current_y[:, :, 0] - y_closest            \n",
    "\n",
    "        deriv = y_rep / (ϵ + tf.math.reduce_euclidean_norm(x_rep, axis=-1, keepdims=True))\n",
    "\n",
    "        dydx_dummy = tf.concat([dydx_dummy, deriv], axis=1)\n",
    "        diff_y_dummy = tf.concat([diff_y_dummy, y_rep], axis=1)\n",
    "        diff_x_dummy = tf.concat([diff_x_dummy, x_rep], axis=1)\n",
    "        closest_y_dummy = tf.concat([closest_y_dummy, y_closest], axis=1)\n",
    "        closest_x_dummy = tf.concat([closest_x_dummy, x_closest], axis=1)\n",
    "\n",
    "        return diff_y_dummy, diff_x_dummy, dydx_dummy, closest_x_dummy, closest_y_dummy\n",
    "\n",
    "\n",
    "    def derivative_function_2d(self, inputs,  ϵ = 0.0000):\n",
    "\n",
    "        \n",
    "            def dydz(current_y, y_closest_1, y_closest_2, current_x, x_closest_1, x_closest_2):\n",
    "                #\"z\" is the second dim of x input\n",
    "                numerator = y_closest_2 - current_y[:, :, 0] - ((x_closest_2[:, :, :1]-current_x[:, :, 0, :1])*(y_closest_1-current_y[:, :, 0] ))/(x_closest_1[:, :, :1]-current_x[:, :, 0, :1] +ϵ)\n",
    "                denom = x_closest_2[:, :, 1:2] - current_x[:, :, 0, 1:2] - (x_closest_1[:, :, 1:2]-current_x[:, :, 0, 1:2])*(x_closest_2[:, :, :1]-current_x[:, :, 0, :1])/(x_closest_1[:, :, :1]-current_x[:, :, 0, :1]+ϵ)\n",
    "                dydz_pred = numerator/(denom+ϵ)\n",
    "                return dydz_pred\n",
    "            \n",
    "            def dydx(dydz, current_y, y_closest_1, current_x, x_closest_1):\n",
    "                dydx = (y_closest_1-current_y[:, :, 0] - dydz*(x_closest_1[:, :, 1:2]-current_x[:, :, 0, 1:2]))/(x_closest_1[:, :, :1]-current_x[:, :, 0, :1]+ϵ)\n",
    "                return dydx\n",
    "\n",
    "            y_values, x_values, n_C, n_T = inputs\n",
    "\n",
    "            batch_size, length = y_values.shape[0], n_C + n_T\n",
    "\n",
    "            dim_x = x_values.shape[-1]\n",
    "            dim_y = y_values.shape[-1]\n",
    "\n",
    "\n",
    "            #context section\n",
    "\n",
    "            current_x = tf.expand_dims(x_values[:, :n_C], axis=2)\n",
    "            current_y = tf.expand_dims(y_values[:, :n_C], axis=2)\n",
    "\n",
    "            x_temp = x_values[:, :n_C]\n",
    "            x_temp = tf.repeat(tf.expand_dims(x_temp, axis=1), axis=1, repeats=n_C)\n",
    "\n",
    "            y_temp = y_values[:, :n_C]\n",
    "            y_temp = tf.repeat(tf.expand_dims(y_temp, axis=1), axis=1, repeats=n_C)\n",
    "\n",
    "            ix_1 = tf.argsort(tf.math.reduce_euclidean_norm((current_x - x_temp), axis=-1), axis=-1)[:, :, 1]        \n",
    "            selection_indices_1 = tf.concat([tf.reshape(tf.repeat(tf.range(batch_size*n_C), 1), (-1, 1)), \n",
    "                                                tf.reshape(ix_1, (-1, 1))], axis=1)\n",
    "\n",
    "            ix_2 = tf.argsort(tf.math.reduce_euclidean_norm((current_x - x_temp), axis=-1), axis=-1)[:, :, 2]        \n",
    "            selection_indices_2 = tf.concat([tf.reshape(tf.repeat(tf.range(batch_size*n_C), 1), (-1, 1)), \n",
    "                                        tf.reshape(ix_2, (-1, 1))], axis=1)\n",
    "\n",
    "\n",
    "            x_closest_1 = tf.reshape(tf.gather_nd(tf.reshape(x_temp, (-1, n_C, dim_x)), selection_indices_1), \n",
    "                                (batch_size, n_C, dim_x)) +   tf.random.normal(shape=(batch_size,  n_C,  dim_x), stddev=0.01)\n",
    "\n",
    "            x_closest_2 = tf.reshape(tf.gather_nd(tf.reshape(x_temp, (-1, n_C, dim_x)), selection_indices_2), \n",
    "                                (batch_size, n_C, dim_x)) +   tf.random.normal(shape=(batch_size, n_C, dim_x), stddev=0.01)\n",
    "\n",
    "\n",
    "\n",
    "            y_closest_1 = tf.reshape(tf.gather_nd(tf.reshape(y_temp, (-1, n_C, dim_y)), selection_indices_1), \n",
    "                        (batch_size, n_C, dim_y))\n",
    "\n",
    "\n",
    "            y_closest_2 = tf.reshape(tf.gather_nd(tf.reshape(y_temp, (-1, n_C, dim_y)), selection_indices_2), \n",
    "                        (batch_size, n_C, dim_y))\n",
    "\n",
    "\n",
    "            x_rep_1 = current_x[:, :, 0] - x_closest_1\n",
    "            x_rep_2 = current_x[:, :, 0] - x_closest_2\n",
    "\n",
    "            print(y_closest_1.shape, current_y.shape)\n",
    "            y_rep_1 = current_y[:, :, 0] - y_closest_1\n",
    "            y_rep_2 = current_y[:, :, 0] - y_closest_2\n",
    "\n",
    "            dydx_2 = dydz(current_y, y_closest_1, y_closest_2, current_x, x_closest_1, x_closest_2)\n",
    "            dydx_1 = dydx(dydx_2, current_y, y_closest_1, current_x, x_closest_1)\n",
    "\n",
    "            deriv_dummy = tf.concat([dydx_1, dydx_2], axis=-1)\n",
    "\n",
    "            diff_y_dummy = tf.concat([y_rep_1, y_rep_2], axis=-1)\n",
    "\n",
    "            diff_x_dummy =tf.concat([x_rep_1, x_rep_2], axis=-1)\n",
    "\n",
    "            closest_y_dummy = tf.concat([y_closest_1, y_closest_2], axis=-1)\n",
    "            closest_x_dummy = tf.concat([x_closest_1, x_closest_2], axis=-1)\n",
    "\n",
    "            #target selection\n",
    "\n",
    "            current_x = tf.expand_dims(x_values[:, n_C:n_C+n_T], axis=2)\n",
    "            current_y = tf.expand_dims(y_values[:, n_C:n_C+n_T], axis=2)\n",
    "\n",
    "            x_temp = tf.repeat(tf.expand_dims(x_values[:, :n_T+n_C], axis=1), axis=1, repeats=n_T)\n",
    "            y_temp = tf.repeat(tf.expand_dims(y_values[:, :n_T+n_C], axis=1), axis=1, repeats=n_T)\n",
    "\n",
    "            \n",
    "            x_mask = 1000  * (1 -  tf.linalg.band_part(tf.ones((n_T, n_C + n_T), tf.int32), -1, n_C))\n",
    "            x_mask_repeat = tf.repeat(x_mask[tf.newaxis, :], axis=0, repeats=batch_size)\n",
    "            \n",
    "            ix_1 = tf.argsort(tf.cast(tf.math.reduce_euclidean_norm((current_x - x_temp), \n",
    "                                                axis=-1), dtype=\"float32\") + x_mask_repeat, axis=-1)[:, :, 1]\n",
    "            selection_indices_1 = tf.concat([tf.reshape(tf.repeat(tf.range(batch_size*n_T), 1), (-1, 1)), \n",
    "                                                tf.reshape(ix_1, (-1, 1))], axis=1)\n",
    "            \n",
    "            \n",
    "            \n",
    "            ix_2 = tf.argsort(tf.cast(tf.math.reduce_euclidean_norm((current_x - x_temp), \n",
    "                                                axis=-1), dtype=\"float32\") + x_mask_repeat, axis=-1)[:, :, 2]\n",
    "            selection_indices_2 = tf.concat([tf.reshape(tf.repeat(tf.range(batch_size*n_T), 1), (-1, 1)), \n",
    "                                                tf.reshape(ix_2, (-1, 1))], axis=1)\n",
    "            \n",
    "            \n",
    "            \n",
    "            x_closest_1 = tf.reshape(tf.gather_nd(tf.reshape(x_temp, (-1, n_T+n_C, dim_x)), selection_indices_1), \n",
    "                                (batch_size, n_T, dim_x)) +   tf.random.normal(shape=(batch_size, n_T, dim_x), stddev=0.01)\n",
    "\n",
    "            x_closest_2 = tf.reshape(tf.gather_nd(tf.reshape(x_temp, (-1, n_T+n_C, dim_x)), selection_indices_2), \n",
    "                                (batch_size, n_T, dim_x)) +   tf.random.normal(shape=(batch_size, n_T, dim_x), stddev=0.01)\n",
    "\n",
    "\n",
    "\n",
    "            y_closest_1 = tf.reshape(tf.gather_nd(tf.reshape(y_temp, (-1, n_T+n_C, dim_y)), selection_indices_1), \n",
    "                        (batch_size, n_T, dim_y))\n",
    "\n",
    "\n",
    "            y_closest_2 = tf.reshape(tf.gather_nd(tf.reshape(y_temp, (-1, n_T+n_C, dim_y)), selection_indices_2), \n",
    "                        (batch_size, n_T, dim_y))\n",
    "        \n",
    "\n",
    "            x_rep_1 = current_x[:, :, 0] - x_closest_1\n",
    "            x_rep_2 = current_x[:, :, 0] - x_closest_2\n",
    "\n",
    "            y_rep_1 = current_y[:, :, 0] - y_closest_1\n",
    "            y_rep_2 = current_y[:, :, 0] - y_closest_2\n",
    "\n",
    "            dydx_2 = dydz(current_y, y_closest_1, y_closest_2, current_x, x_closest_1, x_closest_2)\n",
    "            dydx_1 = dydx(dydx_2, current_y, y_closest_1, current_x, x_closest_1)\n",
    "            \n",
    "            deriv_dummy_2 = tf.concat([dydx_1, dydx_2], axis=-1)\n",
    "\n",
    "            diff_y_dummy_2 = tf.concat([y_rep_1, y_rep_2], axis=-1)\n",
    "\n",
    "            diff_x_dummy_2 =tf.concat([x_rep_1, x_rep_2], axis=-1)\n",
    "\n",
    "            closest_y_dummy_2 = tf.concat([y_closest_1, y_closest_2], axis=-1)\n",
    "            closest_x_dummy_2 = tf.concat([x_closest_1, x_closest_2], axis=-1)\n",
    "            \n",
    "            ########## concat all ############\n",
    "\n",
    "\n",
    "            deriv_dummy_full = tf.concat([deriv_dummy, deriv_dummy_2], axis=1)\n",
    "            diff_y_dummy_full = tf.concat([diff_y_dummy, diff_y_dummy_2], axis=1)\n",
    "            diff_x_dummy_full = tf.concat([diff_x_dummy, diff_x_dummy_2], axis=1)\n",
    "            closest_y_dummy_full = tf.concat([closest_y_dummy, closest_y_dummy_2], axis=1)\n",
    "            closest_x_dummy_full = tf.concat([closest_x_dummy, closest_x_dummy_2], axis=1)\n",
    "\n",
    "            return diff_y_dummy_full, diff_x_dummy_full, deriv_dummy_full, closest_x_dummy_full, closest_y_dummy_full\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "df4f1913",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = DE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e8f27c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(240, 240), dtype=bool, numpy=\n",
       "array([[ True,  True,  True, ..., False, False, False],\n",
       "       [ True,  True,  True, ..., False, False, False],\n",
       "       [ True,  True,  True, ..., False, False, False],\n",
       "       ...,\n",
       "       [ True,  True,  True, ..., False, False, False],\n",
       "       [ True,  True,  True, ...,  True, False, False],\n",
       "       [ True,  True,  True, ...,  True,  True, False]])>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4cd6d216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 1920)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "31a71292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 240)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "906c30ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 1)\n",
      "please add shape information to inputs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 21:26:34.626375: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at strided_slice_op.cc:108 : INVALID_ARGUMENT: Index out of range using input dim 2; input has only 2 dims\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Exception encountered when calling layer \"de_1\" (type DE).\n\nIndex out of range using input dim 2; input has only 2 dims [Op:StridedSlice] name: de_1/strided_slice/\n\nCall arguments received:\n  • inputs=['tf.Tensor(shape=(30, 240), dtype=float32)', 'tf.Tensor(shape=(30, 1), dtype=float32)', 'tf.Tensor(shape=(), dtype=int32)', 'tf.Tensor(shape=(), dtype=int32)', 'tf.Tensor(shape=(), dtype=bool)']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m/Users/omernivron/Documents/ATP/bias_correction_atp.ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/omernivron/Documents/ATP/bias_correction_atp.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(y\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/omernivron/Documents/ATP/bias_correction_atp.ipynb#X25sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     y_diff, x_diff, d, x_n, y_n \u001b[39m=\u001b[39m dd([y[i\u001b[39m*\u001b[39;49m(n_C \u001b[39m+\u001b[39;49m n_T):(i\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m*\u001b[39;49m(n_C \u001b[39m+\u001b[39;49m n_T)], t[i\u001b[39m*\u001b[39;49m(n_C \u001b[39m+\u001b[39;49m n_T):(i\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m*\u001b[39;49m(n_C \u001b[39m+\u001b[39;49m n_T), \u001b[39m0\u001b[39;49m][:, np\u001b[39m.\u001b[39;49mnewaxis], n_C, n_T, \u001b[39mTrue\u001b[39;49;00m])\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_m1_n/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "\u001b[1;32m/Users/omernivron/Documents/ATP/bias_correction_atp.ipynb Cell 17\u001b[0m in \u001b[0;36mDE.call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/omernivron/Documents/ATP/bias_correction_atp.ipynb#X25sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(x\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/omernivron/Documents/ATP/bias_correction_atp.ipynb#X25sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mif\u001b[39;00m (x\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/omernivron/Documents/ATP/bias_correction_atp.ipynb#X25sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     y_diff,  x_diff,  d,  x_n,  y_n \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mderivative_function([y,  x,  n_C,  n_T])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/omernivron/Documents/ATP/bias_correction_atp.ipynb#X25sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39melse\u001b[39;00m: \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/omernivron/Documents/ATP/bias_correction_atp.ipynb#X25sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     y_diff,  x_diff,  d,  x_n,  y_n \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mderivative_function_2d([y,  x,  n_C,  n_T])\n",
      "\u001b[1;32m/Users/omernivron/Documents/ATP/bias_correction_atp.ipynb Cell 17\u001b[0m in \u001b[0;36mDE.derivative_function\u001b[0;34m(self, inputs, ε)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/omernivron/Documents/ATP/bias_correction_atp.ipynb#X25sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m y_temp \u001b[39m=\u001b[39m y_values[:, :n_C]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/omernivron/Documents/ATP/bias_correction_atp.ipynb#X25sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m y_temp \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mrepeat(tf\u001b[39m.\u001b[39mexpand_dims(y_temp,  axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m),  axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,  repeats\u001b[39m=\u001b[39mn_C)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/omernivron/Documents/ATP/bias_correction_atp.ipynb#X25sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m ix \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49margsort(tf\u001b[39m.\u001b[39;49mmath\u001b[39m.\u001b[39;49mreduce_euclidean_norm((current_x \u001b[39m-\u001b[39;49m x_temp), axis\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m), axis\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)[:, :, \u001b[39m1\u001b[39;49m]        \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/omernivron/Documents/ATP/bias_correction_atp.ipynb#X25sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m selection_indices \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconcat([tf\u001b[39m.\u001b[39mreshape(tf\u001b[39m.\u001b[39mrepeat(tf\u001b[39m.\u001b[39mrange(batch_size\u001b[39m*\u001b[39mn_C), \u001b[39m1\u001b[39m), (\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)), \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/omernivron/Documents/ATP/bias_correction_atp.ipynb#X25sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m                                tf\u001b[39m.\u001b[39mreshape(ix, (\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m))], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/omernivron/Documents/ATP/bias_correction_atp.ipynb#X25sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m x_closest \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mreshape(tf\u001b[39m.\u001b[39mgather_nd(tf\u001b[39m.\u001b[39mreshape(x_temp, (\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, n_C, dim_x)), selection_indices), \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/omernivron/Documents/ATP/bias_correction_atp.ipynb#X25sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m                        (batch_size, n_C, dim_x)) \n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Exception encountered when calling layer \"de_1\" (type DE).\n\nIndex out of range using input dim 2; input has only 2 dims [Op:StridedSlice] name: de_1/strided_slice/\n\nCall arguments received:\n  • inputs=['tf.Tensor(shape=(30, 240), dtype=float32)', 'tf.Tensor(shape=(30, 1), dtype=float32)', 'tf.Tensor(shape=(), dtype=int32)', 'tf.Tensor(shape=(), dtype=int32)', 'tf.Tensor(shape=(), dtype=bool)']"
     ]
    }
   ],
   "source": [
    "for i in range(y.shape[1] - 1):\n",
    "    y_diff, x_diff, d, x_n, y_n = dd([y[i*(n_C + n_T):(i+1)*(n_C + n_T)], t[i*(n_C + n_T):(i+1)*(n_C + n_T), 0][:, np.newaxis], n_C, n_T, True])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33af1bf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
