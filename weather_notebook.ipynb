{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import atp_graph, losses\n",
    "from Tutorials.helper import batcher\n",
    "from data import synthetic_data_gen, feature_extractor\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import IPython\n",
    "import time\n",
    "import os\n",
    "\n",
    "from model import atp_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import dataset_preparer\n",
    "\n",
    "#dataset - [weather,traffic,...]\n",
    "\n",
    "#hyperparams - num_heads,..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_processor = dataset_preparer.weather(path_to_weather_data=\"datasets/weather.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_val, y_val, x_test, y_test = weather_processor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"weights/forecasting/weather\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_heads = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(442)\n",
    "opt = tf.keras.optimizers.Adam(3e-4)\n",
    "run=3; heads=2\n",
    "atp_model = atp_pipeline.atp_pipeline(num_heads=num_heads)\n",
    "EPOCHS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_l = 96+192;\n",
    "num_batches = 500\n",
    "batch_s=20\n",
    "mini = 50000\n",
    "n_C_te =5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 1\n",
    "tr_step = atp_graph.build_graph()\n",
    "\n",
    "name_comp = 'run_' + str(run)\n",
    "logdir = save_dir + '/logs/' + name_comp\n",
    "folder = save_dir + '/ckpt/check_' + name_comp\n",
    "\n",
    "if not os.path.exists(folder): os.mkdir(folder)\n",
    "ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=opt, net=atp_model)\n",
    "manager = tf.train.CheckpointManager(ckpt, folder, max_to_keep=1)\n",
    "ckpt.restore(manager.latest_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for epoch in range(2):\n",
    "    print(\"epoch: \",+epoch)\n",
    "    start = time.time()\n",
    "    for batch_n in range(10):\n",
    "         \n",
    "        x,y = batcher(training_data_scaled[:,:1],training_data_scaled[:,-2:])\n",
    "        n_C = int(np.random.choice(np.arange(2, 20), 1))\n",
    "        n_T = 288 - n_C\n",
    "        y_tr = y\n",
    "        t_tr = x\n",
    "        _,_, nll_pp, msex = tr_step(atp_model, opt, t_tr,y_tr,n_C,n_T, training=True)\n",
    "\n",
    "        if ((batch_n % 2 == 0)):\n",
    "            \n",
    "            n_C = 10\n",
    "            n_T = 200 - n_C\n",
    "            t_te,y_te = batcher(val_data_scaled[:,:1], val_data_scaled[:,-2:],batch_s = 100)\n",
    "            μ, log_σ = atp_model([t_te, y_te, 10, 200, False])\n",
    "            _,_,_, nll_pp_te, msex_te = losses.nll(y_te[:, n_C:n_C+n_T], μ[:, n_C:], log_σ[:, n_C:])\n",
    "            \n",
    "        if nll_pp_te < mini:\n",
    "            mini = nll_pp_te\n",
    "            IPython.display.clear_output(wait=True)\n",
    "            print(\"epoch {} batch {} validation lik pp: {}\".format(epoch, batch_n, nll_pp)) \n",
    "            manager.save()\n",
    "            step += 1\n",
    "            ckpt.step.assign_add(1)\n",
    "    print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "testing.testing_multiple_times([training_data_scaled, test_data_scaled], save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "        training_data_scaled, test_data_scaled = inputs\n",
    "        #instantiation\n",
    "        \n",
    "        step = 1\n",
    "        run=run_num; \n",
    "        tf.random.set_seed(run)\n",
    "        opt = tf.keras.optimizers.Adam(3e-4)\n",
    "        atp_model = atp_pipeline.atp_pipeline( num_heads=num_heads, projection_shape_for_head=projection_shape_for_head, output_shape=output_shape, rate=rate, permutation_repeats=permutation_repeats,\n",
    "        bound_std=bound_std, num_layers=num_layers, enc_dim=enc_dim,  xmin=xmin, xmax=xmax)\n",
    "        tr_step = atp_graph.build_graph()\n",
    "        name_comp = 'run_' + str(run)\n",
    "        folder = save_dir + '/ckpt/check_' + name_comp\n",
    "        if not os.path.exists(folder): os.mkdir(folder)\n",
    "        ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=opt, net=atp_model)\n",
    "        manager = tf.train.CheckpointManager(ckpt, folder, max_to_keep=1)\n",
    "        ckpt.restore(manager.latest_checkpoint) \n",
    "        sum_mse_tot = 0; sum_nll_tot = 0\n",
    "        mini = =50000\n",
    "        \n",
    "        #training\n",
    "        for epoch in range(num_epochs):\n",
    "            print(\"epoch: \",+epoch)\n",
    "            for _ in range(num_batches):\n",
    "                x,y = batcher(training_data_scaled[:,:1],training_data_scaled[:,-2:])\n",
    "                n_C = int(np.random.choice(np.arange(2, 20), 1))\n",
    "                n_T = 288 - n_C\n",
    "                _,_, _, _ = tr_step(atp_model, opt, x,y,n_C,n_T, training=True)\n",
    "                \n",
    "                #saving \n",
    "                \n",
    "                if nll_pp_te < mini:\n",
    "                    mini = nll_pp_te\n",
    "                    manager.save()\n",
    "                    step += 1\n",
    "                    ckpt.step.assign_add(1)\n",
    "        \n",
    "        ckpt.restore(manager.latest_checkpoint) \n",
    "\n",
    "\n",
    "        for _ in range(test_data_scaled.shape[0] // test_batch_s):\n",
    "            n_C = 10\n",
    "            n_T = 200 - n_C\n",
    "            t_te,y_te = batcher(test_data_scaled[:,:1], test_data_scaled[:,-2:], batch_s = test_batch_s)\n",
    "            μ, log_σ = atp_model([t_te,y_te,10,200, False])\n",
    "            _, sum_mse, sum_nll, _, _ = losses.nll(y_te[:, n_C:n_C+n_T], μ[:, n_C:], log_σ[:, n_C:])\n",
    "            sum_nll_tot += sum_nll # each sequence is length 190 times 100 seq. per batch \n",
    "            sum_mse_tot += sum_mse\n",
    "            \n",
    "        nllx =  sum_nll_tot / (n_T * test_batch_s * (test_data_scaled.shape[0] // test_batch_s))\n",
    "        msex =  sum_mse_tot / (n_T * test_batch_s * (test_data_scaled.shape[0] // test_batch_s))\n",
    "        \n",
    "            \n",
    "        nll_list.append(nllx.numpy())\n",
    "        mse_list.append(msex.numpy())\n",
    "    np.save(save_dir + '/nll_list.npy', nll_list)    \n",
    "    np.save(save_dir + '/mse_list.npy', mse_list)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "\n",
    "#electricity\n",
    "\n",
    "# make batcher as a function of n_C and n_T - window\n",
    "\n",
    "## other NP experiments\n",
    "\n",
    "# test on n_C and n_T which are randomly selected at each point - outside batcher \n",
    "\n",
    "# don't repeat testing points  \n",
    "\n",
    "# for NP experiments, we need to batch differently. for forecasting 100000 x1 ---> 32 x 288 x 1.\n",
    "# for np, we will have 10000 x 288 x 1 -> 32 x 288 x 1\n",
    "\n",
    "#also divide mse by n_T each batch for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### set this up for training and saving best models adn then loading it and calculating loglik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batcher(t, y, idx_list,batch_s = 32, window = 288,cut_sequence = True):\n",
    "    '''\n",
    "    cutting one long array to sequences of length 'window'.\n",
    "    'batch_s' must be ≤ full array - window length\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    if len(idx_list) < 1:\n",
    "        print(\"warning- you didn't loop over the correct range\")\n",
    "        \n",
    "    \n",
    "    batch_s = min(batch_s, y.shape[0]-window)    \n",
    "    idx = np.random.choice(len(idx_list), batch_s, replace = False)\n",
    "\n",
    "    y = np.array([np.array(y)[idx_list[i]:idx_list[i]+window] for i in idx])\n",
    "    t = np.array([np.array(t)[idx_list[i]:idx_list[i]+window] for i in idx])\n",
    "    for i in sorted(idx, reverse=True): del idx_list[i]\n",
    "    return t, y,idx_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr = Y[tr_ix, :, :]\n",
    "t_tr = t[tr_ix, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batcher(t, y, idx_list, batch_s = 32, window = 288):\n",
    "    '''\n",
    "    cutting one long array to sequences of length 'window'.\n",
    "    'batch_s' must be ≤ full array - window length\n",
    "\n",
    "    input to forecast: (None, 1, 1) for t,y.\n",
    "    input to NP tasks: (None, seq_len, 1) for t,y.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    if len(idx_list) < 1:\n",
    "        print(\"warning- you didn't loop over the correct range\")\n",
    "        \n",
    "    \n",
    "    batch_s = min(batch_s, y.shape[0]-window)    \n",
    "    idx = np.random.choice(len(idx_list), batch_s, replace = False)\n",
    "\n",
    "    y = np.array([np.array(y)[idx_list[i]:idx_list[i]+window, :, :] for i in idx])\n",
    "    t = np.array([np.array(t)[idx_list[i]:idx_list[i]+window, :, :] for i in idx])\n",
    "    for i in sorted(idx, reverse=True): del idx_list[i]\n",
    "        \n",
    "    t = t.squeeze()\n",
    "    y = y.squeeze()\n",
    "    \n",
    "    if len(t.shape) == 2:\n",
    "        t = t[:,:,np.newaxis]\n",
    "        y = y[:,:,np.newaxis]\n",
    "        \n",
    "    return t,y, idx_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_list=list(range(y_test.shape[0]-288))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c = batcher(x_test[:,:,np.newaxis],y_test[:,:,np.newaxis],idx_list=idx_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dummy = np.random.normal(size=(100,300,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dummy = np.random.normal(size=(100,300,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_list=list(range(y_dummy.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dummy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c = batcher(x_dummy,y_dummy,idx_list=idx_list,window=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## start here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import atp_graph, losses\n",
    "from data import synthetic_data_gen, feature_extractor\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from model import atp_pipeline\n",
    "from data import dataset_preparer\n",
    "import argparse\n",
    "from Tutorials.helper import batcher\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_val, y_val, x_test, y_test = dataset_preparer.weather_processor(path_to_weather_data=\"datasets/weather.csv\") \n",
    "save_dir = \"weights/forecasting/weather\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_C = 100\n",
    "n_T = 100\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(3e-4)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_list = list(range(x_train.shape[0] - (n_C+n_T)))\n",
    "x, y, _ = batcher(x_train, y_train, idx_list, window=n_C+n_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batcher_x(t, y, idx_list, batch_s = 32, window = 288):\n",
    "    '''\n",
    "    cutting one long array to sequences of length 'window'.\n",
    "    'batch_s' must be ≤ full array - window length\n",
    "\n",
    "    input to forecast: (None, 1, 1) for t,y.\n",
    "    input to NP tasks: (None, seq_len, 1) for t,y. window = 1.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    if len(idx_list) < 1:\n",
    "        print(\"warning- you didn't loop over the correct range\")\n",
    "        \n",
    "    \n",
    "    batch_s = min(batch_s, y.shape[0]-window)    \n",
    "    idx = np.random.choice(len(idx_list), batch_s, replace = False)\n",
    "\n",
    "    print(idx)\n",
    "    y = np.array([np.array(y)[idx_list[i]:idx_list[i]+window, :, :] for i in idx])\n",
    "    t = np.array([np.array(t)[idx_list[i]:idx_list[i]+window, :, :] for i in idx])\n",
    "    print(t.shape)\n",
    "    for i in sorted(idx, reverse=True): del idx_list[i]\n",
    "        \n",
    "    t = t.squeeze()\n",
    "    y = y.squeeze()\n",
    "    \n",
    "    if len(t.shape) == 2:\n",
    "        t = t[:,:,np.newaxis]\n",
    "        y = y[:,:,np.newaxis]\n",
    "        \n",
    "    return t,y, idx_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_list_v = list(range(x_val.shape[0] - (n_C+n_T)))\n",
    "t_te,y_te,_ = batcher_x(x_val, y_val, idx_list_v, batch_s = 100, window=(n_C+n_T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "step = 1\n",
    "run= 50 + 0\n",
    "tf.random.set_seed(run)\n",
    "atp_model = atp_pipeline.instantiate_atp(\"weather\")\n",
    "tr_step = atp_graph.build_graph()\n",
    "name_comp = 'run_' + str(run)\n",
    "folder = save_dir + '/ckpt/check_' + name_comp\n",
    "if not os.path.exists(folder): os.mkdir(folder)\n",
    "ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=opt, net=atp_model)\n",
    "manager = tf.train.CheckpointManager(ckpt, folder, max_to_keep=1)\n",
    "ckpt.restore(manager.latest_checkpoint) \n",
    "sum_mse_tot = 0; sum_nll_tot = 0\n",
    "mini = 50000\n",
    "\n",
    "for i in range(2):\n",
    "    idx_list = list(range(x_train.shape[0]))\n",
    "    x,y,_ = batcher(x_train,y_train,idx_list,window=n_C+n_T) ####### generalise for not weather\n",
    "    _,_, _, _ = tr_step(atp_model, opt, x,y,n_C,n_T, training=True)\n",
    "\n",
    "    if i % 1 == 0:\n",
    "        idx_list = list(range(x_val.shape[0]))\n",
    "        t_te,y_te,_ = batcher(x_val,y_val,idx_list,batch_s = 100,window=n_C+n_T)\n",
    "        μ, log_σ = atp_model([t_te, y_te, n_C, n_T, False])\n",
    "        _,_,_, nll_pp_te, msex_te = losses.nll(y_te[:, n_C:n_C+n_T], μ, log_σ)\n",
    "\n",
    "        if nll_pp_te < mini:\n",
    "            mini = nll_pp_te\n",
    "            manager.save()\n",
    "            step += 1\n",
    "            ckpt.step.assign_add(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_te,y_te,_ = batcher(x_train,y_train,idx_list,batch_s = 32,window=n_C+n_T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_te.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_te.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
