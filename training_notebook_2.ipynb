{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import atp_graph, losses\n",
    "from data_wrangler import synthetic_data_gen, feature_extractor\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from model import atp_pipeline\n",
    "from comparison_models.tnp import tnp_pipeline\n",
    "from data_wrangler import dataset_preparer\n",
    "import argparse\n",
    "from data_wrangler.batcher import batcher, batcher_np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"exchange\"\n",
    "model = \"atp\"\n",
    "iterations = 300\n",
    "num_repeats = 1\n",
    "n_C = 96\n",
    "n_T = 336"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make sure to create the exchange folder in weights/forecasting/\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if dataset == \"exchange\":\n",
    "    x_train, y_train, x_val, y_val, x_test, y_test = dataset_preparer.dataset_processor(path_to_data=\"datasets/exchange.csv\") \n",
    "    save_dir = \"weights/forecasting/exchange\"\n",
    "    print('make sure to create the exchange folder in weights/forecasting/')\n",
    "else: \n",
    "    raise ValueError(\"Dataset not found\")\n",
    "    \n",
    "save_dir = save_dir + \"/\" + model\n",
    "\n",
    "    \n",
    "batch_size = 32\n",
    "test_batch_s = 100\n",
    "\n",
    "nll_list = []\n",
    "mse_list = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"weights/dummy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'datasets/rbf/x.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x_train, y_train, x_val, y_val, x_test, y_test,_ \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_preparer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgp_data_processor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_to_data_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdatasets/rbf/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ATP/data_wrangler/dataset_preparer.py:58\u001b[0m, in \u001b[0;36mgp_data_processor\u001b[0;34m(path_to_data_folder)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgp_data_processor\u001b[39m(path_to_data_folder):\n\u001b[0;32m---> 58\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_to_data_folder\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mx.npy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m         y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(path_to_data_folder \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     61\u001b[0m         x_train \u001b[38;5;241m=\u001b[39m x[:\u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m0.99\u001b[39m\u001b[38;5;241m*\u001b[39mx\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])]\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_m1_n/lib/python3.8/site-packages/numpy/lib/npyio.py:390\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    388\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 390\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    391\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'datasets/rbf/x.npy'"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_val, y_val, x_test, y_test,_ = dataset_preparer.gp_data_processor(path_to_data_folder=\"datasets/rbf/\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TNP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "step = 1\n",
    "run= 50 + i\n",
    "tf.random.set_seed(run)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = tnp_pipeline.tnp_pipeline(num_heads=6,projection_shape_for_head=8,output_shape=48, dropout_rate=0.1, \n",
    "                 permutation_repeats=0,bound_std=False, num_layers=6,target_y_dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 1\n",
    "\n",
    "model = tnp_pipeline.tnp_pipeline(num_heads=6,projection_shape_for_head=16,output_shape=32, dropout_rate=0.0, \n",
    "                 permutation_repeats=1,bound_std=False, num_layers=6,target_y_dim=1)\n",
    "                 \n",
    "Best val score:  0.12        \n",
    "\n",
    "Model 2 \n",
    "\n",
    "model = tnp_pipeline.tnp_pipeline(num_heads=6,projection_shape_for_head=16,output_shape=32, dropout_rate=0.2, \n",
    "                 permutation_repeats=1,bound_std=False, num_layers=6,target_y_dim=1)\n",
    "                 \n",
    "Best val score: 0.11\n",
    "\n",
    "\n",
    "\n",
    "Modle 4\n",
    "model = tnp_pipeline.tnp_pipeline(num_heads=6,projection_shape_for_head=8,output_shape=48, dropout_rate=0.05, \n",
    "                 permutation_repeats=1,bound_std=False, num_layers=6,target_y_dim=1)\n",
    "     \n",
    "     \n",
    "0.099\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Model 7\n",
    "\n",
    "\n",
    "model = tnp_pipeline.tnp_pipeline(num_heads=6,projection_shape_for_head=12,output_shape=16, dropout_rate=0.1, \n",
    "                 permutation_repeats=1,bound_std=False, num_layers=6,target_y_dim=1)\n",
    "                 \n",
    "                 \n",
    "0.22            \n",
    "\n",
    "Model 8\n",
    "\n",
    "model = tnp_pipeline.tnp_pipeline(num_heads=6,projection_shape_for_head=12,output_shape=16, dropout_rate=0.25, \n",
    "                 permutation_repeats=1,bound_std=False, num_layers=6,target_y_dim=1)\n",
    "                 \n",
    "0.04    \n",
    "\n",
    "Model 9 \n",
    "\n",
    "model = tnp_pipeline.tnp_pipeline(num_heads=6,projection_shape_for_head=8,output_shape=48, dropout_rate=0.05, \n",
    "                 permutation_repeats=0,bound_std=False, num_layers=6,target_y_dim=1)\n",
    "\n",
    "\n",
    "-0.6\n",
    "\n",
    "Model 10 \n",
    "\n",
    "\n",
    "model = tnp_pipeline.tnp_pipeline(num_heads=6,projection_shape_for_head=12,output_shape=16, dropout_rate=0.15, \n",
    "                 permutation_repeats=0,bound_std=False, num_layers=6,target_y_dim=1)\n",
    "                 \n",
    "Use model 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_T = 720"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = []\n",
    "train_array = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_list = list(range(x_train.shape[0] - (n_C+n_T)))\n",
    "x,y,_ = batcher(x_train,y_train,idx_list,window=n_C+n_T,batch_s=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "μ, log_σ = model([x, y, n_C, n_T, False])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "μ.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    run = 54\n",
    "    tr_step = atp_graph.build_graph()\n",
    "\n",
    "    ###### can we put the name of the model into the folder name #########?\n",
    "\n",
    "    name_comp = 'run_' + str(run)\n",
    "    folder = save_dir + '/ckpt/check_' + name_comp\n",
    "    if not os.path.exists(folder): os.mkdir(folder)\n",
    "    opt = tf.keras.optimizers.Adam(3e-4)\n",
    "    ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=opt, net=model)\n",
    "    manager = tf.train.CheckpointManager(ckpt, folder, max_to_keep=1)\n",
    "    ckpt.restore(manager.latest_checkpoint) \n",
    "    sum_mse_tot = 0; sum_nll_tot = 0\n",
    "    mini = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(2000):\n",
    "    idx_list = list(range(x_train.shape[0] - (n_C+n_T)))\n",
    "    _,y,_ = batcher(x_train,y_train,idx_list,window=n_C+n_T) ####### generalise for not just forecasting\n",
    "    x = np.repeat(np.linspace(-1,1,(n_C+n_T))[np.newaxis,:,np.newaxis],axis=0,repeats=32)\n",
    "    #### edit batcher to fix this\n",
    "    _,_, nll_pp_tr, _ = tr_step(model, opt, x,y,n_C,n_T, training=True)\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        train_array.append(nll_pp_tr)\n",
    "        idx_list = list(range(x_val.shape[0] - (n_C+n_T)))\n",
    "        _,y_te,_ = batcher(x_val,y_val,idx_list,batch_s = 100,window=n_C+n_T)\n",
    "        t_te = np.repeat(np.linspace(-1,1,(n_C+n_T))[np.newaxis,:,np.newaxis],axis=0,repeats=100)\n",
    "        μ, log_σ = model([t_te, y_te, n_C, n_T, False])\n",
    "        _,_,_, nll_pp_te, msex_te = losses.nll(y_te[:, n_C:n_C+n_T], μ, log_σ)\n",
    "        array.append(nll_pp_te)\n",
    "        \n",
    "        plt.plot(train_array)\n",
    "        plt.plot(array)\n",
    "        plt.show()\n",
    "\n",
    "        print(nll_pp_te)\n",
    "        print(min(array))\n",
    "\n",
    "        if nll_pp_te < mini:\n",
    "            mini = nll_pp_te\n",
    "            manager.save()\n",
    "            step += 1\n",
    "            ckpt.step.assign_add(1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = tf.train.Checkpoint(step=tf.Variable(step), optimizer=opt, net=model)\n",
    "manager = tf.train.CheckpointManager(ckpt, folder, max_to_keep=1)\n",
    "ckpt.restore(manager.latest_checkpoint) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_list = list(range(x_val.shape[0] - (n_C+n_T)))\n",
    "\n",
    "t_te,y_te,_ = batcher(x_val,y_val,idx_list,batch_s = 100,window=n_C+n_T)\n",
    "μ, log_σ = model([t_te, y_te, n_C, n_T, False])\n",
    "_,_,_, nll_pp_te, msex_te = losses.nll(y_te[:, n_C:n_C+n_T], μ, log_σ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nll_pp_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_te[1,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_mse_tot = 0; sum_nll_tot = 0\n",
    "\n",
    "idx_list = list(range(x_test.shape[0] - (n_C+n_T)))\n",
    "num_batches = len(idx_list)//test_batch_s\n",
    "t_te,y_te,idx_list = batcher(x_test, y_test, idx_list,batch_s = test_batch_s, window=n_C+n_T)\n",
    "μ, log_σ = model([t_te, y_te, n_C, n_T, False])\n",
    "_,_,_, nll_pp_te, msex_te = losses.nll(y_te[:, n_C:n_C+n_T], μ, log_σ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nll_pp_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msex_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mean = np.mean(y_te[:,:96],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mean_repeat = np.repeat(y_mean[:,np.newaxis,:],axis=1,repeats=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean((y_te[:,96:] - y_mean_repeat)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch_s = 100\n",
    "\n",
    "sum_mse_tot = 0; sum_nll_tot = 0\n",
    "\n",
    "idx_list = list(range(x_test.shape[0] - (n_C+n_T)))\n",
    "num_batches = len(idx_list)//test_batch_s\n",
    "\n",
    "for _ in range(num_batches): #### specify correct number of batches for the batcher #####\n",
    "    if(_ == (num_batches-1)): test_batch_s = len(idx_list)        \n",
    "    _,y_te,idx_list = batcher(x_test, y_test, idx_list,batch_s = test_batch_s, window=n_C+n_T)\n",
    "    t_te = np.repeat(np.linspace(-1,1,(n_C+n_T))[np.newaxis,:,np.newaxis],axis=0,repeats=y_te.shape[0])\n",
    "    μ, log_σ = model([t_te, y_te, n_C, n_T, False])\n",
    "    _, sum_mse, sum_nll, _, _ = losses.nll(y_te[:, n_C:n_C+n_T], μ, log_σ)\n",
    "    sum_nll_tot += sum_nll / n_T\n",
    "    sum_mse_tot += sum_mse / n_T\n",
    "\n",
    "nllx =  sum_nll_tot / (test_batch_s * x_test.shape[0]//test_batch_s)\n",
    "msex =  sum_mse_tot / (test_batch_s * x_test.shape[0]//test_batch_s)\n",
    "\n",
    "print(msex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nllx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_te[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_list = list(range(x_val.shape[0] - (n_C+n_T)))\n",
    "t_te,y_te,_ = batcher(x_val,y_val,idx_list,batch_s = 100,window=n_C+n_T)\n",
    "μ, log_σ = model([t_te, y_te, n_C, n_T, False])\n",
    "_, sum_mse, sum_nll, _, _ = losses.nll(y_te[:, n_C:n_C+n_T], μ, log_σ)\n",
    "print(sum_nll/n_T/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_te[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_test[:,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_val[:,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_nll/n_T/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nllx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.load(\"weights/forecasting/exchange/tnp/ckpt/check_run_2/validation_losses_iteration.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.load(\"weights/forecasting/exchange/atp/ckpt/check_run_2/validation_losses_iteration.npy\")\n",
    "plt.plot(array)\n",
    "np.min(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.load(\"weights/forecasting/exchange/atp/nll_list.npy\")\n",
    "array\n",
    "array.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.load(\"weights/forecasting/exchange/tnp/nll_list.npy\")\n",
    "array\n",
    "array.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# atp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "step = 1\n",
    "run= 50 + i\n",
    "tf.random.set_seed(run)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 1\n",
    "\n",
    "model = atp_pipeline.atp_pipeline(num_heads=6, projection_shape_for_head=8, output_shape=32, rate=0.1, permutation_repeats=0,\n",
    "                 bound_std=False, num_layers=3, enc_dim=32, xmin=0.1, xmax=2)\n",
    "                 \n",
    "-1.3\n",
    "\n",
    "Model 2\n",
    "\n",
    "model = atp_pipeline.atp_pipeline(num_heads=7, projection_shape_for_head=15, output_shape=32, rate=0.1, permutation_repeats=0,\n",
    "                 bound_std=False, num_layers=3, enc_dim=32, xmin=0.1, xmax=1)\n",
    "                 \n",
    "-1.35\n",
    "\n",
    "Model 3\n",
    "\n",
    "model = atp_pipeline.atp_pipeline(num_heads=6, projection_shape_for_head=12, output_shape=32, rate=0.0, permutation_repeats=0,\n",
    "                 bound_std=False, num_layers=4, enc_dim=32, xmin=0.1, xmax=1)\n",
    "\n",
    "-1.35\n",
    "\n",
    "Model 4 \n",
    "\n",
    "model = atp_pipeline.atp_pipeline(num_heads=6, projection_shape_for_head=9, output_shape=32, rate=0.0, permutation_repeats=0,\n",
    "                 bound_std=False, num_layers=4, enc_dim=32, xmin=0.1, xmax=1,MHAX_leakage=False)\n",
    "                 \n",
    "-1.34\n",
    "\n",
    "Model 5\n",
    "\n",
    "model = atp_pipeline.atp_pipeline(num_heads=3, projection_shape_for_head=9, output_shape=32, rate=0.0, permutation_repeats=0,\n",
    "                 bound_std=False, num_layers=6, enc_dim=32, xmin=0.1, xmax=1,MHAX_leakage=False)\n",
    "                 \n",
    "-1.35\n",
    "\n",
    "Model 6 \n",
    "\n",
    "model = atp_pipeline.atp_pipeline(num_heads=10, projection_shape_for_head=9, output_shape=32, rate=0.0, permutation_repeats=0,\n",
    "                 bound_std=False, num_layers=6, enc_dim=32, xmin=0.1, xmax=1,MHAX_leakage=\"new_block\")\n",
    "\n",
    "-1.33\n",
    "\n",
    "Model 7\n",
    "\n",
    "-1.31\n",
    "\n",
    "Model 8  \n",
    "\n",
    "model = atp_pipeline.atp_pipeline(num_heads=8, projection_shape_for_head=12, output_shape=32, rate=0.0, permutation_repeats=0,\n",
    "                 bound_std=False, num_layers=3, enc_dim=32, xmin=0.1, xmax=1,MHAX_leakage=\"xxx\")\n",
    "\n",
    "-1.34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 15:19:16.165197: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-05-09 15:19:16.165755: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Max\n",
      "(32, 336, 432)\n",
      "(32, 336)\n",
      "Model: \"atp_pipeline\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " feature_wrapper (feature_wr  multiple                 0         \n",
      " apper)                                                          \n",
      "                                                                 \n",
      " atp (ATP)                   multiple                  88270     \n",
      "                                                                 \n",
      " de (DE)                     multiple                  4         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 88,274\n",
      "Trainable params: 88,272\n",
      "Non-trainable params: 2\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model = atp_pipeline.atp_pipeline(num_heads=8, projection_shape_for_head=12, output_shape=32, rate=0.0,\n",
    "#                                   permutation_repeats=0,\n",
    "#                  bound_std=False, num_layers=3, enc_dim=32, xmin=0.1, xmax=1,MHAX_leakage=\"xxx\")\n",
    "\n",
    "\n",
    "\n",
    "model = atp_pipeline.atp_pipeline(num_heads=10, projection_shape_for_head=9, output_shape=32, rate=0.05, permutation_repeats=0,\n",
    "                 bound_std=False, num_layers=6, enc_dim=32, xmin=0.1, xmax=1,MHAX_leakage=\"new_block\")\n",
    "\n",
    "array = []\n",
    "train_array = []\n",
    "\n",
    "idx_list = list(range(x_train.shape[0] - (n_C+n_T)))\n",
    "x,y,_ = batcher(x_train,y_train,idx_list,window=n_C+n_T)\n",
    "\n",
    "μ, log_σ = model([x, y, n_C, n_T, False])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    run = 202\n",
    "    tr_step = atp_graph.build_graph()\n",
    "\n",
    "    ###### can we put the name of the model into the folder name #########?\n",
    "\n",
    "    name_comp = 'run_' + str(run)\n",
    "    folder = save_dir + '/ckpt/check_' + name_comp\n",
    "    if not os.path.exists(folder): os.mkdir(folder)\n",
    "    opt = tf.keras.optimizers.Adam(3e-4)\n",
    "    ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=opt, net=model)\n",
    "    manager = tf.train.CheckpointManager(ckpt, folder, max_to_keep=1)\n",
    "    ckpt.restore(manager.latest_checkpoint) \n",
    "    sum_mse_tot = 0; sum_nll_tot = 0\n",
    "    mini = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2000):\n",
    "    idx_list = list(range(x_train.shape[0] - (n_C+n_T)))\n",
    "    _,y,_ = batcher(x_train,y_train,idx_list,window=n_C+n_T) ####### generalise for not just forecasting\n",
    "    x = np.repeat(np.linspace(-1,1,(n_C+n_T))[np.newaxis,:,np.newaxis],axis=0,repeats=32)\n",
    "    #### edit batcher to fix this\n",
    "    _,_, nll_pp_tr, _ = tr_step(model, opt, x,y,n_C,n_T, training=True)\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        train_array.append(nll_pp_tr)\n",
    "        idx_list = list(range(x_val.shape[0] - (n_C+n_T)))\n",
    "        _,y_te,_ = batcher(x_val,y_val,idx_list,batch_s = 100,window=n_C+n_T)\n",
    "        t_te = np.repeat(np.linspace(-1,1,(n_C+n_T))[np.newaxis,:,np.newaxis],axis=0,repeats=100)\n",
    "        μ, log_σ = model([t_te, y_te, n_C, n_T, False])\n",
    "        _,_,_, nll_pp_te, msex_te = losses.nll(y_te[:, n_C:n_C+n_T], μ, log_σ)\n",
    "        array.append(nll_pp_te)\n",
    "        \n",
    "        plt.plot(train_array)\n",
    "        plt.plot(array)\n",
    "        plt.show()\n",
    "\n",
    "        print(nll_pp_te)\n",
    "        print(min(array))\n",
    "\n",
    "        if nll_pp_te < mini:\n",
    "            mini = nll_pp_te\n",
    "            manager.save()\n",
    "            step += 1\n",
    "            ckpt.step.assign_add(1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = tf.train.Checkpoint(step=tf.Variable(step), optimizer=opt, net=model)\n",
    "manager = tf.train.CheckpointManager(ckpt, folder, max_to_keep=1)\n",
    "ckpt.restore(manager.latest_checkpoint) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch_s = 100\n",
    "\n",
    "sum_mse_tot = 0; sum_nll_tot = 0\n",
    "\n",
    "idx_list = list(range(x_test.shape[0] - (n_C+n_T)))\n",
    "num_batches = len(idx_list)//test_batch_s\n",
    "\n",
    "for _ in range(num_batches): #### specify correct number of batches for the batcher #####\n",
    "    if(_ == (num_batches-1)): test_batch_s = len(idx_list)        \n",
    "    _,y_te,idx_list = batcher(x_test, y_test, idx_list,batch_s = test_batch_s, window=n_C+n_T)\n",
    "    t_te = np.repeat(np.linspace(-1,1,(n_C+n_T))[np.newaxis,:,np.newaxis],axis=0,repeats=y_te.shape[0])\n",
    "    μ, log_σ = model([t_te, y_te, n_C, n_T, False])\n",
    "    _, sum_mse, sum_nll, _, _ = losses.nll(y_te[:, n_C:n_C+n_T], μ, log_σ)\n",
    "    sum_nll_tot += sum_nll / n_T\n",
    "    sum_mse_tot += sum_mse / n_T\n",
    "\n",
    "nllx =  sum_nll_tot / (test_batch_s * x_test.shape[0]//test_batch_s)\n",
    "msex =  sum_mse_tot / (test_batch_s * x_test.shape[0]//test_batch_s)\n",
    "\n",
    "print(msex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "step = 1\n",
    "run= 50 + i\n",
    "tf.random.set_seed(run)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_C = 10\n",
    "n_T = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 1 \n",
    "\n",
    "model = atp_pipeline.atp_pipeline(num_heads=3, projection_shape_for_head=10, output_shape=32, rate=0.0, permutation_repeats=0,\n",
    "                 bound_std=False, num_layers=6, enc_dim=32, xmin=0.1, xmax=1,MHAX_leakage=True)\n",
    "\n",
    "-0.61\n",
    "\n",
    "Model 2\n",
    "\n",
    "model = atp_pipeline.atp_pipeline(num_heads=3, projection_shape_for_head=9, output_shape=32, rate=0.0, permutation_repeats=0,\n",
    "                 bound_std=False, num_layers=5, enc_dim=32, xmin=0.1, xmax=1,MHAX_leakage=False)\n",
    "\n",
    "-0.7\n",
    "\n",
    "Model 3 \n",
    "\n",
    "model = atp_pipeline.atp_pipeline(num_heads=10, projection_shape_for_head=9, output_shape=32, rate=0.0, permutation_repeats=0,\n",
    "                 bound_std=False, num_layers=6, enc_dim=32, xmin=0.1, xmax=2,MHAX_leakage=\"new_block\")\n",
    "                 \n",
    "-0.87\n",
    "\n",
    "Model 4 \n",
    "\n",
    "model = atp_pipeline.atp_pipeline(num_heads=8, projection_shape_for_head=12, output_shape=32, rate=0.0, permutation_repeats=0,\n",
    "                 bound_std=False, num_layers=3, enc_dim=32, xmin=0.1, xmax=1,MHAX_leakage=\"xxx\")\n",
    "\n",
    "-1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = atp_pipeline.atp_pipeline(num_heads=10, projection_shape_for_head=9, output_shape=32, rate=0.0, permutation_repeats=0,\n",
    "                 bound_std=False, num_layers=6, enc_dim=32, xmin=0.1, xmax=2,MHAX_leakage=\"new_block\")\n",
    "            \n",
    "array = []\n",
    "train_array = []\n",
    "\n",
    "idx_list = list(range(x_train.shape[0] - (n_C+n_T)))\n",
    "x,y, = batcher_np(x_train,y_train)\n",
    "\n",
    "μ, log_σ = model([x, y, n_C, n_T, False])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    run = 5\n",
    "    tr_step = atp_graph.build_graph()\n",
    "\n",
    "    ###### can we put the name of the model into the folder name #########?\n",
    "\n",
    "    name_comp = 'run_' + str(run)\n",
    "    folder = save_dir + '/ckpt/check_' + name_comp\n",
    "    if not os.path.exists(folder): os.mkdir(folder)\n",
    "    opt = tf.keras.optimizers.Adam(3e-4)\n",
    "    ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=opt, net=model)\n",
    "    manager = tf.train.CheckpointManager(ckpt, folder, max_to_keep=1)\n",
    "    ckpt.restore(manager.latest_checkpoint) \n",
    "    sum_mse_tot = 0; sum_nll_tot = 0\n",
    "    mini = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4000):\n",
    "    idx_list = list(range(x_train.shape[0] - (n_C+n_T)))\n",
    "    x,y = batcher_np(x_train,y_train)\n",
    "    _,_, nll_pp_tr, _ = tr_step(model, opt, x,y,n_C,n_T, training=True)\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        train_array.append(nll_pp_tr)\n",
    "        t_te,y_te = batcher_np(x_val,y_val,batch_s = 100)\n",
    "        μ, log_σ = model([t_te, y_te, n_C, n_T, False])\n",
    "        _,_,_, nll_pp_te, msex_te = losses.nll(y_te[:, n_C:n_C+n_T], μ, log_σ)\n",
    "        array.append(nll_pp_te)\n",
    "        \n",
    "        plt.plot(train_array)\n",
    "        plt.plot(array)\n",
    "        plt.show()\n",
    "\n",
    "        print(nll_pp_te)\n",
    "        print(min(array))\n",
    "\n",
    "        if nll_pp_te < mini:\n",
    "            mini = nll_pp_te\n",
    "            manager.save()\n",
    "            step += 1\n",
    "            ckpt.step.assign_add(1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
