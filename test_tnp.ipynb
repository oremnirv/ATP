{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import dot_prod\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "####### need to import dot_prod.py from ATP/model/ #######\n",
    "\n",
    "class FFN(tf.keras.layers.Layer):\n",
    "    def __init__(self, output_shape, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dense_b = tf.keras.layers.Dense(output_shape)\n",
    "        self.dense_c = tf.keras.layers.Dense(output_shape)\n",
    "        self.layernorm = [tf.keras.layers.LayerNormalization() for _ in range(2)]        \n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, x, query):\n",
    "\n",
    "      ## query is the output of previous MHA_X layer\n",
    "      ## x is query input to MHA_X_o \n",
    "\n",
    "        x += query\n",
    "        x = self.layernorm[0](x)\n",
    "        x_skip = tf.identity(x)\n",
    "        x = self.dense_b(x)\n",
    "        x = tf.nn.gelu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense_c(x)\n",
    "        x += x_skip\n",
    "        return self.layernorm[1](x)\n",
    "\n",
    "class MHA_XY(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 num_heads,\n",
    "                  projection_shape,\n",
    "                  output_shape,\n",
    "                  dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.mha = dot_prod.MultiHeadAttention(num_heads, output_shape, projection_shape)\n",
    "        self.ffn = FFN(output_shape, dropout_rate)\n",
    "\n",
    "    def call(self, query, key, value, mask):\n",
    "        x = self.mha(query, key, value, mask)\n",
    "        x = self.ffn(x, query)  # Shape `(batch_size, seq_len, output_shape)`.\n",
    "        return x\n",
    "    \n",
    "\n",
    "class embed_layers(tf.keras.layers.Layer):\n",
    "    def __init__(self,output_shape,num_layers_embed=4):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers_embed\n",
    "        self.embed = [tf.keras.layers.Dense(output_shape,activation=\"relu\") for _ in range(num_layers_embed-1)]\n",
    "        self.embed.append(tf.keras.layers.Dense(output_shape))\n",
    "\n",
    "    def call(self,inputs):\n",
    "        x = inputs\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.embed[i](x)\n",
    "        return x\n",
    "\n",
    "class TNP_Decoder(tf.keras.models.Model):\n",
    "    def __init__(self,output_shape=64,num_layers=6,projection_shape=16,\n",
    "                 num_heads=4,dropout_rate=0.0,target_y_dim=1,bound_std=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.mha_xy = [MHA_XY(num_heads,projection_shape,\n",
    "                              output_shape,dropout_rate) for _ in range(num_layers)]\n",
    "\n",
    "        self.embed = embed_layers(output_shape,num_layers_embed=4)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(output_shape,activation=\"relu\")\n",
    "        self.linear = tf.keras.layers.Dense(2*target_y_dim)\n",
    "        self.target_y_dim = target_y_dim\n",
    "        self.bound_std = bound_std\n",
    "        \n",
    "    def call(self,inputs,training=True):\n",
    "\n",
    "        ####### check that using training flag like this does prevent dropout\n",
    "        ### when it is set to false\n",
    "        \n",
    "        context_target_pairs,target_masked_pairs,mask = inputs\n",
    "        input_for_mha = tf.concat([context_target_pairs,target_masked_pairs],axis=1)\n",
    "\n",
    "        embed = self.embed(input_for_mha)\n",
    "        \n",
    "        v = embed\n",
    "        k = tf.identity(v)\n",
    "        q = tf.identity(v)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.mha_xy[i](q,k,v,mask)\n",
    "            q = tf.identity(x)\n",
    "            k = tf.identity(x)\n",
    "            v = tf.identity(x)\n",
    "      \n",
    "        L = self.dense(x)\n",
    "        L = self.linear(L)\n",
    "\n",
    "        mean,log_sigma = L[:,:,:self.target_y_dim],L[:,:,self.target_y_dim:]\n",
    "\n",
    "        if self.bound_std:\n",
    "            sigma = 0.05 + 0.95 * tf.math.softplus(log_sigma)\n",
    "        else:\n",
    "            sigma = tf.exp(log_sigma)\n",
    "        \n",
    "        log_sigma = tf.math.log(sigma)\n",
    "        return mean,log_sigma      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "tnp_model = TNP_Decoder(output_shape=4,num_layers=2,projection_shape=4*3,\n",
    "                 num_heads=4,dropout_rate=0.1,target_y_dim=1,bound_std=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.normal(size=(2,20,1))\n",
    "y = np.random.normal(size=(2,20,1))\n",
    "n_C = 3\n",
    "n_T = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        x = x[:,:n_C+n_T,:]\n",
    "        y = y[:,:n_C+n_T,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        context_part = tf.concat([tf.ones((n_C,n_C),tf.bool),tf.zeros((n_C,2*n_T),tf.bool)],\n",
    "                         axis=-1)\n",
    "        first_part = tf.linalg.band_part(tf.ones((n_T,n_C+2*n_T),tf.bool),-1,n_C)\n",
    "        second_part = tf.linalg.band_part(tf.ones((n_T,n_C+2*n_T),tf.bool),-1,n_C-1)\n",
    "        mask = tf.concat([context_part,first_part,second_part],axis=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "        batch_s = tf.shape(x)[0]\n",
    "\n",
    "        context_target_pairs = tf.concat([x,y],axis=2)\n",
    "        \n",
    "        y_masked = tf.zeros((batch_s,n_T,y.shape[-1]))\n",
    "        target_masked_pairs = tf.concat([x[:,n_C:],y_masked],axis=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 17, 1), dtype=float32, numpy=\n",
       " array([[[0.44684225],\n",
       "         [0.7466157 ],\n",
       "         [0.80075735],\n",
       "         [0.90359604],\n",
       "         [0.48757184],\n",
       "         [0.4199815 ],\n",
       "         [0.48619607],\n",
       "         [0.427507  ],\n",
       "         [0.41764975],\n",
       "         [0.86133313],\n",
       "         [0.44897962],\n",
       "         [0.44548956],\n",
       "         [0.42017996],\n",
       "         [0.47749928],\n",
       "         [0.4582056 ],\n",
       "         [0.49849993],\n",
       "         [0.42031136]],\n",
       " \n",
       "        [[0.4165408 ],\n",
       "         [0.733211  ],\n",
       "         [0.52880526],\n",
       "         [0.9691214 ],\n",
       "         [0.4716235 ],\n",
       "         [0.92942685],\n",
       "         [0.38826334],\n",
       "         [0.916807  ],\n",
       "         [0.35382468],\n",
       "         [0.9291175 ],\n",
       "         [0.40406883],\n",
       "         [0.35289133],\n",
       "         [0.35821268],\n",
       "         [0.32225105],\n",
       "         [0.3457569 ],\n",
       "         [0.3155364 ],\n",
       "         [0.3388884 ]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 17, 1), dtype=float32, numpy=\n",
       " array([[[-0.20082581],\n",
       "         [-0.33149752],\n",
       "         [-0.3544551 ],\n",
       "         [-0.3971118 ],\n",
       "         [-0.21913104],\n",
       "         [-0.18740514],\n",
       "         [-0.21851271],\n",
       "         [-0.1921359 ],\n",
       "         [-0.18454772],\n",
       "         [-0.37986732],\n",
       "         [-0.20178644],\n",
       "         [-0.2002179 ],\n",
       "         [-0.18727848],\n",
       "         [-0.21460411],\n",
       "         [-0.20593287],\n",
       "         [-0.22404248],\n",
       "         [-0.1870237 ]],\n",
       " \n",
       "        [[-0.16421205],\n",
       "         [-0.32440263],\n",
       "         [-0.23647489],\n",
       "         [-0.42397076],\n",
       "         [-0.21196334],\n",
       "         [-0.4079193 ],\n",
       "         [-0.18877688],\n",
       "         [-0.40281445],\n",
       "         [-0.18497361],\n",
       "         [-0.40770376],\n",
       "         [-0.15273468],\n",
       "         [-0.15853111],\n",
       "         [-0.14012088],\n",
       "         [-0.16049132],\n",
       "         [-0.14534079],\n",
       "         [-0.17393833],\n",
       "         [-0.16997017]]], dtype=float32)>)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tnp_model([context_target_pairs,target_masked_pairs,mask],training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:updated_tf]",
   "language": "python",
   "name": "conda-env-updated_tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
